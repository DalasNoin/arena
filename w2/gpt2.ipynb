{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers\n",
    "# ! wget https://raw.githubusercontent.com/callummcdougall/arena-v1/main/w2d2/utils.py\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import GELU, Softmax\n",
    "from dataclasses import dataclass\n",
    "import transformers\n",
    "import utils\n",
    "import matplotlib\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TransformerConfig:\n",
    "    '''Constants used throughout your decoder-only transformer model.'''\n",
    "\n",
    "    num_layers: int = 12\n",
    "    # head_size is not in this config, because in our implementation we're assuming num_heads * head_size = hidden_size\n",
    "    num_heads: int = 12\n",
    "    vocab_size: int = 50_257\n",
    "    # hidden_size is also referred to as embedding_dim, or d_\\text{model}d model in some material you might have read.\n",
    "    hidden_size: int = 768\n",
    "    # max_seq_len is used just to determine the size of the positional encoding matrix.\n",
    "    max_seq_len: int = 1024\n",
    "    dropout: float = 0.1\n",
    "    layer_norm_epsilon: float = 1e-05\n",
    "    device: str = \"cpu\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define gpt2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2MLP(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.dropout = config.dropout\n",
    "        self.mlp_block = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, 4*self.hidden_size),\n",
    "            GELU(),\n",
    "            nn.Linear(4*self.hidden_size, self.hidden_size),\n",
    "            nn.Dropout(self.dropout)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.mlp_block(x)\n",
    "\n",
    "Q = torch.ones((2,20,4*64))\n",
    "K = torch.ones((2,10,4*64))\n",
    "V = torch.ones((2,10,4*64))\n",
    "num_heads = 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPT2Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    head_size is not in this config, because in our implementation we're assuming num_heads * head_size = hidden_size.\n",
    "    hidden_size is also referred to as embedding_dim, or d_\\text{model}d \n",
    "    model in some material you might have read.\n",
    "\n",
    "    I ignored this for now as it would require changing the masked attention function\n",
    "    The attention block has two dropout layers: \n",
    "    one immediately after the softmax (i.e. before multiplying by V), \n",
    "    and one immediately after multiplying with W_O at the very end of the attention block. \n",
    "    Note that the dropout layers won't actually affect weight-loading or performance in eval mode \n",
    "    (and you should still be able to train your model without them), \n",
    "    but all the same it's nice to be able to exactly match GPT's architecture!\n",
    "    \"\"\"\n",
    "    W_QKV: nn.Linear\n",
    "    W_O: nn.Linear\n",
    "\n",
    "\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.num_heads = config.num_heads\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.device = config.device\n",
    "        self.head_size = self.hidden_size // self.num_heads\n",
    "        self.W_QKV = nn.Linear(self.hidden_size, self.num_heads*self.head_size*3)\n",
    "        self.dropout1 = nn.Dropout(config.dropout)\n",
    "        self.W_O = nn.Linear(self.num_heads*self.head_size, self.hidden_size)\n",
    "        self.dropout2 = nn.Dropout(config.dropout)\n",
    "        self.softmax = Softmax(dim=3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        x: shape (batch, seq, hidden_size)\n",
    "\n",
    "        Return: shape (batch, seq, hidden_size)\n",
    "        '''\n",
    "        # x = x.repeat((1,1,3)) # repeat trice along dim 2\n",
    "        x = self.W_QKV(x)\n",
    "        #print(f\"{x.shape=} {num_heads=} {self.hidden_size=}\")\n",
    "        Q, K, V = torch.split(x, self.num_heads*self.head_size, 2)\n",
    "        #print(f\"{Q.shape=} {K.shape=} {V.shape=}\")\n",
    "        \n",
    "        # Z = multihead_masked_attention(Q, K, V, num_heads=self.num_heads, device=self.device)\n",
    "        batch, target_seq_len = Q.shape[0:2]\n",
    "        source_seq_len = K.shape[1] \n",
    "        head_size = int(Q.shape[-1]/self.num_heads)\n",
    "        sqrt_d_k = torch.sqrt(torch.tensor(self.head_size))\n",
    "        # new_shape = (batch, target_seq_len, num_heads, head_size)\n",
    "        Q = torch.reshape(Q, (batch, target_seq_len, self.num_heads, self.head_size))\n",
    "        K = torch.reshape(K, (batch, source_seq_len, self.num_heads, self.head_size))\n",
    "        V = torch.reshape(V, (batch, source_seq_len, self.num_heads, self.head_size))\n",
    "        # generate mask\n",
    "        triangular = torch.triu(torch.ones((target_seq_len, source_seq_len), dtype=torch.bool, device=self.device), diagonal=1)\n",
    "        \n",
    "        query_key = torch.einsum(\"abcd,aecd->acbe\", Q, K)\n",
    "        masked_query_key = torch.where(triangular, -torch.inf, query_key)\n",
    "        masked_query_key = self.softmax((masked_query_key)/sqrt_d_k)\n",
    "        masked_query_key = self.dropout1(masked_query_key)\n",
    "        result = torch.einsum(\"abcd, adbe-> acbe\", masked_query_key, V)\n",
    "        Z = torch.reshape(result, (batch, target_seq_len, self.num_heads * self.head_size))\n",
    "        Z = self.dropout2(Z)\n",
    "        #print(f\"{Z.shape=}\")\n",
    "        Z = self.W_O(Z)\n",
    "        return Z\n",
    "\n",
    "class GPT2BlockSimon(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_epsilon)\n",
    "        self.attn = GPT2Attention(config)\n",
    "        self.ln2 = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_epsilon)\n",
    "        self.mlp = GPT2MLP(config)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPT2Model(nn.Module):\n",
    "\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.text_embedding = nn.Embedding(\n",
    "            num_embeddings=self.config.vocab_size,\n",
    "            embedding_dim=self.config.hidden_size)\n",
    "        self.position_embedding = nn.Embedding(\n",
    "            num_embeddings=self.config.max_seq_len,\n",
    "            embedding_dim=self.config.hidden_size\n",
    "        )\n",
    "        list_decoder_blocks = [GPT2BlockSimon(config = self.config) \n",
    "                                    for _ in range(self.config.num_layers)]\n",
    "        self.decoder_blocks = nn.Sequential(*list_decoder_blocks)\n",
    "        self.final_layer_norm = nn.LayerNorm(normalized_shape=self.config.hidden_size,eps=self.config.layer_norm_epsilon)\n",
    "        # self.unembed = nn.Linear(self.config.hidden_size, config.vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if len(x.shape) == 1:\n",
    "            x = torch.unsqueeze(x, dim=0)\n",
    "        position = torch.arange(x.shape[1], device=self.config.device)\n",
    "        x = self.text_embedding(x) + self.position_embedding(position)\n",
    "        # print(f\"x.shape={x.shape}\")\n",
    "        x = self.decoder_blocks(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        # x = self.unembed(x) # ,dim=2)\n",
    "        x = x @ self.text_embedding.weight.T\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformerConfig()\n",
    "model = GPT2Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = transformers.AutoModelForCausalLM.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting some tools from week 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining keys = []\n",
      "len(pretraineddict)=148\tlen(my_state)=148\n",
      "Model 1, total params = 124439808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/kj835tbs6k90jwrl3w9bsmmm0000gn/T/ipykernel_51312/855470895.py:26: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3281.)\n",
      "  shape = pretraineddict[key].T.shape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>shape_1</th>\n",
       "      <th>num_params_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text_embedding.weight</td>\n",
       "      <td>(50257, 768)</td>\n",
       "      <td>38597376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>position_embedding.weight</td>\n",
       "      <td>(1024, 768)</td>\n",
       "      <td>786432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decoder_blocks.0.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decoder_blocks.0.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decoder_blocks.0.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "      <td>1769472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>decoder_blocks.11.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>decoder_blocks.11.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>2359296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>decoder_blocks.11.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>final_layer_norm.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>final_layer_norm.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name_1       shape_1  num_params_1\n",
       "0                       text_embedding.weight  (50257, 768)      38597376\n",
       "1                   position_embedding.weight   (1024, 768)        786432\n",
       "2                 decoder_blocks.0.ln1.weight        (768,)           768\n",
       "3                   decoder_blocks.0.ln1.bias        (768,)           768\n",
       "4          decoder_blocks.0.attn.W_QKV.weight   (2304, 768)       1769472\n",
       "..                                        ...           ...           ...\n",
       "143    decoder_blocks.11.mlp.mlp_block.0.bias       (3072,)          3072\n",
       "144  decoder_blocks.11.mlp.mlp_block.2.weight   (768, 3072)       2359296\n",
       "145    decoder_blocks.11.mlp.mlp_block.2.bias        (768,)           768\n",
       "146                   final_layer_norm.weight        (768,)           768\n",
       "147                     final_layer_norm.bias        (768,)           768\n",
       "\n",
       "[148 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2, total params = 124439808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_params_2</th>\n",
       "      <th>shape_2</th>\n",
       "      <th>name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38597376</td>\n",
       "      <td>(50257, 768)</td>\n",
       "      <td>transformer.wte.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>786432</td>\n",
       "      <td>(1024, 768)</td>\n",
       "      <td>transformer.wpe.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>transformer.h.0.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>768</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>transformer.h.0.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1769472</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>transformer.h.0.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3072</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>transformer.h.11.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2359296</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>transformer.h.11.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>768</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>transformer.h.11.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>768</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>transformer.ln_f.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>768</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>transformer.ln_f.bias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_params_2       shape_2                              name_2\n",
       "0        38597376  (50257, 768)              transformer.wte.weight\n",
       "1          786432   (1024, 768)              transformer.wpe.weight\n",
       "2             768        (768,)         transformer.h.0.ln_1.weight\n",
       "3             768        (768,)           transformer.h.0.ln_1.bias\n",
       "4         1769472   (768, 2304)  transformer.h.0.attn.c_attn.weight\n",
       "..            ...           ...                                 ...\n",
       "143          3072       (3072,)      transformer.h.11.mlp.c_fc.bias\n",
       "144       2359296   (3072, 768)  transformer.h.11.mlp.c_proj.weight\n",
       "145           768        (768,)    transformer.h.11.mlp.c_proj.bias\n",
       "146           768        (768,)             transformer.ln_f.weight\n",
       "147           768        (768,)               transformer.ln_f.bias\n",
       "\n",
       "[148 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameter counts match!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d5b4c_row0_col2, #T_d5b4c_row0_col3 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d5b4c_row1_col2, #T_d5b4c_row1_col3 {\n",
       "  background-color: #2cb17e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d5b4c_row2_col2, #T_d5b4c_row2_col3, #T_d5b4c_row3_col2, #T_d5b4c_row3_col3, #T_d5b4c_row7_col2, #T_d5b4c_row7_col3, #T_d5b4c_row8_col2, #T_d5b4c_row8_col3, #T_d5b4c_row9_col2, #T_d5b4c_row9_col3, #T_d5b4c_row13_col2, #T_d5b4c_row13_col3, #T_d5b4c_row14_col2, #T_d5b4c_row14_col3, #T_d5b4c_row15_col2, #T_d5b4c_row15_col3, #T_d5b4c_row19_col2, #T_d5b4c_row19_col3, #T_d5b4c_row20_col2, #T_d5b4c_row20_col3, #T_d5b4c_row21_col2, #T_d5b4c_row21_col3, #T_d5b4c_row25_col2, #T_d5b4c_row25_col3, #T_d5b4c_row26_col2, #T_d5b4c_row26_col3, #T_d5b4c_row27_col2, #T_d5b4c_row27_col3, #T_d5b4c_row31_col2, #T_d5b4c_row31_col3, #T_d5b4c_row32_col2, #T_d5b4c_row32_col3, #T_d5b4c_row33_col2, #T_d5b4c_row33_col3, #T_d5b4c_row37_col2, #T_d5b4c_row37_col3, #T_d5b4c_row38_col2, #T_d5b4c_row38_col3, #T_d5b4c_row39_col2, #T_d5b4c_row39_col3, #T_d5b4c_row43_col2, #T_d5b4c_row43_col3, #T_d5b4c_row44_col2, #T_d5b4c_row44_col3, #T_d5b4c_row45_col2, #T_d5b4c_row45_col3, #T_d5b4c_row49_col2, #T_d5b4c_row49_col3, #T_d5b4c_row50_col2, #T_d5b4c_row50_col3, #T_d5b4c_row51_col2, #T_d5b4c_row51_col3, #T_d5b4c_row55_col2, #T_d5b4c_row55_col3, #T_d5b4c_row56_col2, #T_d5b4c_row56_col3, #T_d5b4c_row57_col2, #T_d5b4c_row57_col3, #T_d5b4c_row61_col2, #T_d5b4c_row61_col3, #T_d5b4c_row62_col2, #T_d5b4c_row62_col3, #T_d5b4c_row63_col2, #T_d5b4c_row63_col3, #T_d5b4c_row67_col2, #T_d5b4c_row67_col3, #T_d5b4c_row68_col2, #T_d5b4c_row68_col3, #T_d5b4c_row69_col2, #T_d5b4c_row69_col3, #T_d5b4c_row73_col2, #T_d5b4c_row73_col3, #T_d5b4c_row74_col2, #T_d5b4c_row74_col3, #T_d5b4c_row75_col2, #T_d5b4c_row75_col3, #T_d5b4c_row79_col2, #T_d5b4c_row79_col3, #T_d5b4c_row80_col2, #T_d5b4c_row80_col3, #T_d5b4c_row81_col2, #T_d5b4c_row81_col3, #T_d5b4c_row85_col2, #T_d5b4c_row85_col3, #T_d5b4c_row86_col2, #T_d5b4c_row86_col3, #T_d5b4c_row87_col2, #T_d5b4c_row87_col3, #T_d5b4c_row91_col2, #T_d5b4c_row91_col3, #T_d5b4c_row92_col2, #T_d5b4c_row92_col3, #T_d5b4c_row93_col2, #T_d5b4c_row93_col3, #T_d5b4c_row97_col2, #T_d5b4c_row97_col3, #T_d5b4c_row98_col2, #T_d5b4c_row98_col3, #T_d5b4c_row99_col2, #T_d5b4c_row99_col3, #T_d5b4c_row103_col2, #T_d5b4c_row103_col3, #T_d5b4c_row104_col2, #T_d5b4c_row104_col3, #T_d5b4c_row105_col2, #T_d5b4c_row105_col3, #T_d5b4c_row109_col2, #T_d5b4c_row109_col3, #T_d5b4c_row110_col2, #T_d5b4c_row110_col3, #T_d5b4c_row111_col2, #T_d5b4c_row111_col3, #T_d5b4c_row115_col2, #T_d5b4c_row115_col3, #T_d5b4c_row116_col2, #T_d5b4c_row116_col3, #T_d5b4c_row117_col2, #T_d5b4c_row117_col3, #T_d5b4c_row121_col2, #T_d5b4c_row121_col3, #T_d5b4c_row122_col2, #T_d5b4c_row122_col3, #T_d5b4c_row123_col2, #T_d5b4c_row123_col3, #T_d5b4c_row127_col2, #T_d5b4c_row127_col3, #T_d5b4c_row128_col2, #T_d5b4c_row128_col3, #T_d5b4c_row129_col2, #T_d5b4c_row129_col3, #T_d5b4c_row133_col2, #T_d5b4c_row133_col3, #T_d5b4c_row134_col2, #T_d5b4c_row134_col3, #T_d5b4c_row135_col2, #T_d5b4c_row135_col3, #T_d5b4c_row139_col2, #T_d5b4c_row139_col3, #T_d5b4c_row140_col2, #T_d5b4c_row140_col3, #T_d5b4c_row141_col2, #T_d5b4c_row141_col3, #T_d5b4c_row145_col2, #T_d5b4c_row145_col3, #T_d5b4c_row146_col2, #T_d5b4c_row146_col3, #T_d5b4c_row147_col2, #T_d5b4c_row147_col3 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d5b4c_row4_col2, #T_d5b4c_row4_col3, #T_d5b4c_row16_col2, #T_d5b4c_row16_col3, #T_d5b4c_row28_col2, #T_d5b4c_row28_col3, #T_d5b4c_row40_col2, #T_d5b4c_row40_col3, #T_d5b4c_row52_col2, #T_d5b4c_row52_col3, #T_d5b4c_row64_col2, #T_d5b4c_row64_col3, #T_d5b4c_row76_col2, #T_d5b4c_row76_col3, #T_d5b4c_row88_col2, #T_d5b4c_row88_col3, #T_d5b4c_row100_col2, #T_d5b4c_row100_col3, #T_d5b4c_row112_col2, #T_d5b4c_row112_col3, #T_d5b4c_row124_col2, #T_d5b4c_row124_col3, #T_d5b4c_row136_col2, #T_d5b4c_row136_col3 {\n",
       "  background-color: #4cc26c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d5b4c_row5_col2, #T_d5b4c_row5_col3, #T_d5b4c_row17_col2, #T_d5b4c_row17_col3, #T_d5b4c_row29_col2, #T_d5b4c_row29_col3, #T_d5b4c_row41_col2, #T_d5b4c_row41_col3, #T_d5b4c_row53_col2, #T_d5b4c_row53_col3, #T_d5b4c_row65_col2, #T_d5b4c_row65_col3, #T_d5b4c_row77_col2, #T_d5b4c_row77_col3, #T_d5b4c_row89_col2, #T_d5b4c_row89_col3, #T_d5b4c_row101_col2, #T_d5b4c_row101_col3, #T_d5b4c_row113_col2, #T_d5b4c_row113_col3, #T_d5b4c_row125_col2, #T_d5b4c_row125_col3, #T_d5b4c_row137_col2, #T_d5b4c_row137_col3 {\n",
       "  background-color: #482475;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d5b4c_row6_col2, #T_d5b4c_row6_col3, #T_d5b4c_row18_col2, #T_d5b4c_row18_col3, #T_d5b4c_row30_col2, #T_d5b4c_row30_col3, #T_d5b4c_row42_col2, #T_d5b4c_row42_col3, #T_d5b4c_row54_col2, #T_d5b4c_row54_col3, #T_d5b4c_row66_col2, #T_d5b4c_row66_col3, #T_d5b4c_row78_col2, #T_d5b4c_row78_col3, #T_d5b4c_row90_col2, #T_d5b4c_row90_col3, #T_d5b4c_row102_col2, #T_d5b4c_row102_col3, #T_d5b4c_row114_col2, #T_d5b4c_row114_col3, #T_d5b4c_row126_col2, #T_d5b4c_row126_col3, #T_d5b4c_row138_col2, #T_d5b4c_row138_col3 {\n",
       "  background-color: #25ac82;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d5b4c_row10_col2, #T_d5b4c_row10_col3, #T_d5b4c_row12_col2, #T_d5b4c_row12_col3, #T_d5b4c_row22_col2, #T_d5b4c_row22_col3, #T_d5b4c_row24_col2, #T_d5b4c_row24_col3, #T_d5b4c_row34_col2, #T_d5b4c_row34_col3, #T_d5b4c_row36_col2, #T_d5b4c_row36_col3, #T_d5b4c_row46_col2, #T_d5b4c_row46_col3, #T_d5b4c_row48_col2, #T_d5b4c_row48_col3, #T_d5b4c_row58_col2, #T_d5b4c_row58_col3, #T_d5b4c_row60_col2, #T_d5b4c_row60_col3, #T_d5b4c_row70_col2, #T_d5b4c_row70_col3, #T_d5b4c_row72_col2, #T_d5b4c_row72_col3, #T_d5b4c_row82_col2, #T_d5b4c_row82_col3, #T_d5b4c_row84_col2, #T_d5b4c_row84_col3, #T_d5b4c_row94_col2, #T_d5b4c_row94_col3, #T_d5b4c_row96_col2, #T_d5b4c_row96_col3, #T_d5b4c_row106_col2, #T_d5b4c_row106_col3, #T_d5b4c_row108_col2, #T_d5b4c_row108_col3, #T_d5b4c_row118_col2, #T_d5b4c_row118_col3, #T_d5b4c_row120_col2, #T_d5b4c_row120_col3, #T_d5b4c_row130_col2, #T_d5b4c_row130_col3, #T_d5b4c_row132_col2, #T_d5b4c_row132_col3, #T_d5b4c_row142_col2, #T_d5b4c_row142_col3, #T_d5b4c_row144_col2, #T_d5b4c_row144_col3 {\n",
       "  background-color: #58c765;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d5b4c_row11_col2, #T_d5b4c_row11_col3, #T_d5b4c_row23_col2, #T_d5b4c_row23_col3, #T_d5b4c_row35_col2, #T_d5b4c_row35_col3, #T_d5b4c_row47_col2, #T_d5b4c_row47_col3, #T_d5b4c_row59_col2, #T_d5b4c_row59_col3, #T_d5b4c_row71_col2, #T_d5b4c_row71_col3, #T_d5b4c_row83_col2, #T_d5b4c_row83_col3, #T_d5b4c_row95_col2, #T_d5b4c_row95_col3, #T_d5b4c_row107_col2, #T_d5b4c_row107_col3, #T_d5b4c_row119_col2, #T_d5b4c_row119_col3, #T_d5b4c_row131_col2, #T_d5b4c_row131_col3, #T_d5b4c_row143_col2, #T_d5b4c_row143_col3 {\n",
       "  background-color: #472d7b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d5b4c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d5b4c_level0_col0\" class=\"col_heading level0 col0\" >name_1</th>\n",
       "      <th id=\"T_d5b4c_level0_col1\" class=\"col_heading level0 col1\" >shape_1</th>\n",
       "      <th id=\"T_d5b4c_level0_col2\" class=\"col_heading level0 col2\" >num_params_1</th>\n",
       "      <th id=\"T_d5b4c_level0_col3\" class=\"col_heading level0 col3\" >num_params_2</th>\n",
       "      <th id=\"T_d5b4c_level0_col4\" class=\"col_heading level0 col4\" >shape_2</th>\n",
       "      <th id=\"T_d5b4c_level0_col5\" class=\"col_heading level0 col5\" >name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d5b4c_row0_col0\" class=\"data row0 col0\" >text_embedding.weight</td>\n",
       "      <td id=\"T_d5b4c_row0_col1\" class=\"data row0 col1\" >(50257, 768)</td>\n",
       "      <td id=\"T_d5b4c_row0_col2\" class=\"data row0 col2\" >38597376</td>\n",
       "      <td id=\"T_d5b4c_row0_col3\" class=\"data row0 col3\" >38597376</td>\n",
       "      <td id=\"T_d5b4c_row0_col4\" class=\"data row0 col4\" >(50257, 768)</td>\n",
       "      <td id=\"T_d5b4c_row0_col5\" class=\"data row0 col5\" >transformer.wte.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d5b4c_row1_col0\" class=\"data row1 col0\" >position_embedding.weight</td>\n",
       "      <td id=\"T_d5b4c_row1_col1\" class=\"data row1 col1\" >(1024, 768)</td>\n",
       "      <td id=\"T_d5b4c_row1_col2\" class=\"data row1 col2\" >786432</td>\n",
       "      <td id=\"T_d5b4c_row1_col3\" class=\"data row1 col3\" >786432</td>\n",
       "      <td id=\"T_d5b4c_row1_col4\" class=\"data row1 col4\" >(1024, 768)</td>\n",
       "      <td id=\"T_d5b4c_row1_col5\" class=\"data row1 col5\" >transformer.wpe.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d5b4c_row2_col0\" class=\"data row2 col0\" >decoder_blocks.0.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row2_col1\" class=\"data row2 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row2_col2\" class=\"data row2 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row2_col3\" class=\"data row2 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row2_col4\" class=\"data row2 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row2_col5\" class=\"data row2 col5\" >transformer.h.0.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d5b4c_row3_col0\" class=\"data row3 col0\" >decoder_blocks.0.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row3_col1\" class=\"data row3 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row3_col2\" class=\"data row3 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row3_col3\" class=\"data row3 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row3_col4\" class=\"data row3 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row3_col5\" class=\"data row3 col5\" >transformer.h.0.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d5b4c_row4_col0\" class=\"data row4 col0\" >decoder_blocks.0.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row4_col1\" class=\"data row4 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row4_col2\" class=\"data row4 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row4_col3\" class=\"data row4 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row4_col4\" class=\"data row4 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row4_col5\" class=\"data row4 col5\" >transformer.h.0.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d5b4c_row5_col0\" class=\"data row5 col0\" >decoder_blocks.0.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row5_col1\" class=\"data row5 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row5_col2\" class=\"data row5 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row5_col3\" class=\"data row5 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row5_col4\" class=\"data row5 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row5_col5\" class=\"data row5 col5\" >transformer.h.0.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d5b4c_row6_col0\" class=\"data row6 col0\" >decoder_blocks.0.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row6_col1\" class=\"data row6 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row6_col2\" class=\"data row6 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row6_col3\" class=\"data row6 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row6_col4\" class=\"data row6 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row6_col5\" class=\"data row6 col5\" >transformer.h.0.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d5b4c_row7_col0\" class=\"data row7 col0\" >decoder_blocks.0.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row7_col1\" class=\"data row7 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row7_col2\" class=\"data row7 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row7_col3\" class=\"data row7 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row7_col4\" class=\"data row7 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row7_col5\" class=\"data row7 col5\" >transformer.h.0.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d5b4c_row8_col0\" class=\"data row8 col0\" >decoder_blocks.0.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row8_col1\" class=\"data row8 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row8_col2\" class=\"data row8 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row8_col3\" class=\"data row8 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row8_col4\" class=\"data row8 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row8_col5\" class=\"data row8 col5\" >transformer.h.0.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d5b4c_row9_col0\" class=\"data row9 col0\" >decoder_blocks.0.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row9_col1\" class=\"data row9 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row9_col2\" class=\"data row9 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row9_col3\" class=\"data row9 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row9_col4\" class=\"data row9 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row9_col5\" class=\"data row9 col5\" >transformer.h.0.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d5b4c_row10_col0\" class=\"data row10 col0\" >decoder_blocks.0.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row10_col1\" class=\"data row10 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row10_col2\" class=\"data row10 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row10_col3\" class=\"data row10 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row10_col4\" class=\"data row10 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row10_col5\" class=\"data row10 col5\" >transformer.h.0.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d5b4c_row11_col0\" class=\"data row11 col0\" >decoder_blocks.0.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row11_col1\" class=\"data row11 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row11_col2\" class=\"data row11 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row11_col3\" class=\"data row11 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row11_col4\" class=\"data row11 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row11_col5\" class=\"data row11 col5\" >transformer.h.0.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d5b4c_row12_col0\" class=\"data row12 col0\" >decoder_blocks.0.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row12_col1\" class=\"data row12 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row12_col2\" class=\"data row12 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row12_col3\" class=\"data row12 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row12_col4\" class=\"data row12 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row12_col5\" class=\"data row12 col5\" >transformer.h.0.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d5b4c_row13_col0\" class=\"data row13 col0\" >decoder_blocks.0.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row13_col1\" class=\"data row13 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row13_col2\" class=\"data row13 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row13_col3\" class=\"data row13 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row13_col4\" class=\"data row13 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row13_col5\" class=\"data row13 col5\" >transformer.h.0.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d5b4c_row14_col0\" class=\"data row14 col0\" >decoder_blocks.1.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row14_col1\" class=\"data row14 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row14_col2\" class=\"data row14 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row14_col3\" class=\"data row14 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row14_col4\" class=\"data row14 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row14_col5\" class=\"data row14 col5\" >transformer.h.1.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d5b4c_row15_col0\" class=\"data row15 col0\" >decoder_blocks.1.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row15_col1\" class=\"data row15 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row15_col2\" class=\"data row15 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row15_col3\" class=\"data row15 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row15_col4\" class=\"data row15 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row15_col5\" class=\"data row15 col5\" >transformer.h.1.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d5b4c_row16_col0\" class=\"data row16 col0\" >decoder_blocks.1.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row16_col1\" class=\"data row16 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row16_col2\" class=\"data row16 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row16_col3\" class=\"data row16 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row16_col4\" class=\"data row16 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row16_col5\" class=\"data row16 col5\" >transformer.h.1.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d5b4c_row17_col0\" class=\"data row17 col0\" >decoder_blocks.1.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row17_col1\" class=\"data row17 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row17_col2\" class=\"data row17 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row17_col3\" class=\"data row17 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row17_col4\" class=\"data row17 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row17_col5\" class=\"data row17 col5\" >transformer.h.1.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d5b4c_row18_col0\" class=\"data row18 col0\" >decoder_blocks.1.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row18_col1\" class=\"data row18 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row18_col2\" class=\"data row18 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row18_col3\" class=\"data row18 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row18_col4\" class=\"data row18 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row18_col5\" class=\"data row18 col5\" >transformer.h.1.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_d5b4c_row19_col0\" class=\"data row19 col0\" >decoder_blocks.1.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row19_col1\" class=\"data row19 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row19_col2\" class=\"data row19 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row19_col3\" class=\"data row19 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row19_col4\" class=\"data row19 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row19_col5\" class=\"data row19 col5\" >transformer.h.1.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_d5b4c_row20_col0\" class=\"data row20 col0\" >decoder_blocks.1.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row20_col1\" class=\"data row20 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row20_col2\" class=\"data row20 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row20_col3\" class=\"data row20 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row20_col4\" class=\"data row20 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row20_col5\" class=\"data row20 col5\" >transformer.h.1.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_d5b4c_row21_col0\" class=\"data row21 col0\" >decoder_blocks.1.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row21_col1\" class=\"data row21 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row21_col2\" class=\"data row21 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row21_col3\" class=\"data row21 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row21_col4\" class=\"data row21 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row21_col5\" class=\"data row21 col5\" >transformer.h.1.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_d5b4c_row22_col0\" class=\"data row22 col0\" >decoder_blocks.1.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row22_col1\" class=\"data row22 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row22_col2\" class=\"data row22 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row22_col3\" class=\"data row22 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row22_col4\" class=\"data row22 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row22_col5\" class=\"data row22 col5\" >transformer.h.1.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_d5b4c_row23_col0\" class=\"data row23 col0\" >decoder_blocks.1.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row23_col1\" class=\"data row23 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row23_col2\" class=\"data row23 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row23_col3\" class=\"data row23 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row23_col4\" class=\"data row23 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row23_col5\" class=\"data row23 col5\" >transformer.h.1.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_d5b4c_row24_col0\" class=\"data row24 col0\" >decoder_blocks.1.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row24_col1\" class=\"data row24 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row24_col2\" class=\"data row24 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row24_col3\" class=\"data row24 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row24_col4\" class=\"data row24 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row24_col5\" class=\"data row24 col5\" >transformer.h.1.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_d5b4c_row25_col0\" class=\"data row25 col0\" >decoder_blocks.1.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row25_col1\" class=\"data row25 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row25_col2\" class=\"data row25 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row25_col3\" class=\"data row25 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row25_col4\" class=\"data row25 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row25_col5\" class=\"data row25 col5\" >transformer.h.1.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_d5b4c_row26_col0\" class=\"data row26 col0\" >decoder_blocks.2.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row26_col1\" class=\"data row26 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row26_col2\" class=\"data row26 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row26_col3\" class=\"data row26 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row26_col4\" class=\"data row26 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row26_col5\" class=\"data row26 col5\" >transformer.h.2.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_d5b4c_row27_col0\" class=\"data row27 col0\" >decoder_blocks.2.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row27_col1\" class=\"data row27 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row27_col2\" class=\"data row27 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row27_col3\" class=\"data row27 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row27_col4\" class=\"data row27 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row27_col5\" class=\"data row27 col5\" >transformer.h.2.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_d5b4c_row28_col0\" class=\"data row28 col0\" >decoder_blocks.2.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row28_col1\" class=\"data row28 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row28_col2\" class=\"data row28 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row28_col3\" class=\"data row28 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row28_col4\" class=\"data row28 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row28_col5\" class=\"data row28 col5\" >transformer.h.2.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_d5b4c_row29_col0\" class=\"data row29 col0\" >decoder_blocks.2.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row29_col1\" class=\"data row29 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row29_col2\" class=\"data row29 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row29_col3\" class=\"data row29 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row29_col4\" class=\"data row29 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row29_col5\" class=\"data row29 col5\" >transformer.h.2.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_d5b4c_row30_col0\" class=\"data row30 col0\" >decoder_blocks.2.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row30_col1\" class=\"data row30 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row30_col2\" class=\"data row30 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row30_col3\" class=\"data row30 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row30_col4\" class=\"data row30 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row30_col5\" class=\"data row30 col5\" >transformer.h.2.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_d5b4c_row31_col0\" class=\"data row31 col0\" >decoder_blocks.2.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row31_col1\" class=\"data row31 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row31_col2\" class=\"data row31 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row31_col3\" class=\"data row31 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row31_col4\" class=\"data row31 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row31_col5\" class=\"data row31 col5\" >transformer.h.2.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_d5b4c_row32_col0\" class=\"data row32 col0\" >decoder_blocks.2.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row32_col1\" class=\"data row32 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row32_col2\" class=\"data row32 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row32_col3\" class=\"data row32 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row32_col4\" class=\"data row32 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row32_col5\" class=\"data row32 col5\" >transformer.h.2.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_d5b4c_row33_col0\" class=\"data row33 col0\" >decoder_blocks.2.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row33_col1\" class=\"data row33 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row33_col2\" class=\"data row33 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row33_col3\" class=\"data row33 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row33_col4\" class=\"data row33 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row33_col5\" class=\"data row33 col5\" >transformer.h.2.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_d5b4c_row34_col0\" class=\"data row34 col0\" >decoder_blocks.2.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row34_col1\" class=\"data row34 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row34_col2\" class=\"data row34 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row34_col3\" class=\"data row34 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row34_col4\" class=\"data row34 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row34_col5\" class=\"data row34 col5\" >transformer.h.2.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_d5b4c_row35_col0\" class=\"data row35 col0\" >decoder_blocks.2.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row35_col1\" class=\"data row35 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row35_col2\" class=\"data row35 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row35_col3\" class=\"data row35 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row35_col4\" class=\"data row35 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row35_col5\" class=\"data row35 col5\" >transformer.h.2.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_d5b4c_row36_col0\" class=\"data row36 col0\" >decoder_blocks.2.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row36_col1\" class=\"data row36 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row36_col2\" class=\"data row36 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row36_col3\" class=\"data row36 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row36_col4\" class=\"data row36 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row36_col5\" class=\"data row36 col5\" >transformer.h.2.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_d5b4c_row37_col0\" class=\"data row37 col0\" >decoder_blocks.2.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row37_col1\" class=\"data row37 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row37_col2\" class=\"data row37 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row37_col3\" class=\"data row37 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row37_col4\" class=\"data row37 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row37_col5\" class=\"data row37 col5\" >transformer.h.2.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_d5b4c_row38_col0\" class=\"data row38 col0\" >decoder_blocks.3.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row38_col1\" class=\"data row38 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row38_col2\" class=\"data row38 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row38_col3\" class=\"data row38 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row38_col4\" class=\"data row38 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row38_col5\" class=\"data row38 col5\" >transformer.h.3.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_d5b4c_row39_col0\" class=\"data row39 col0\" >decoder_blocks.3.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row39_col1\" class=\"data row39 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row39_col2\" class=\"data row39 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row39_col3\" class=\"data row39 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row39_col4\" class=\"data row39 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row39_col5\" class=\"data row39 col5\" >transformer.h.3.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_d5b4c_row40_col0\" class=\"data row40 col0\" >decoder_blocks.3.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row40_col1\" class=\"data row40 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row40_col2\" class=\"data row40 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row40_col3\" class=\"data row40 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row40_col4\" class=\"data row40 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row40_col5\" class=\"data row40 col5\" >transformer.h.3.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_d5b4c_row41_col0\" class=\"data row41 col0\" >decoder_blocks.3.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row41_col1\" class=\"data row41 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row41_col2\" class=\"data row41 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row41_col3\" class=\"data row41 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row41_col4\" class=\"data row41 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row41_col5\" class=\"data row41 col5\" >transformer.h.3.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_d5b4c_row42_col0\" class=\"data row42 col0\" >decoder_blocks.3.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row42_col1\" class=\"data row42 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row42_col2\" class=\"data row42 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row42_col3\" class=\"data row42 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row42_col4\" class=\"data row42 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row42_col5\" class=\"data row42 col5\" >transformer.h.3.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_d5b4c_row43_col0\" class=\"data row43 col0\" >decoder_blocks.3.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row43_col1\" class=\"data row43 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row43_col2\" class=\"data row43 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row43_col3\" class=\"data row43 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row43_col4\" class=\"data row43 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row43_col5\" class=\"data row43 col5\" >transformer.h.3.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_d5b4c_row44_col0\" class=\"data row44 col0\" >decoder_blocks.3.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row44_col1\" class=\"data row44 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row44_col2\" class=\"data row44 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row44_col3\" class=\"data row44 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row44_col4\" class=\"data row44 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row44_col5\" class=\"data row44 col5\" >transformer.h.3.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_d5b4c_row45_col0\" class=\"data row45 col0\" >decoder_blocks.3.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row45_col1\" class=\"data row45 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row45_col2\" class=\"data row45 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row45_col3\" class=\"data row45 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row45_col4\" class=\"data row45 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row45_col5\" class=\"data row45 col5\" >transformer.h.3.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_d5b4c_row46_col0\" class=\"data row46 col0\" >decoder_blocks.3.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row46_col1\" class=\"data row46 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row46_col2\" class=\"data row46 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row46_col3\" class=\"data row46 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row46_col4\" class=\"data row46 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row46_col5\" class=\"data row46 col5\" >transformer.h.3.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_d5b4c_row47_col0\" class=\"data row47 col0\" >decoder_blocks.3.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row47_col1\" class=\"data row47 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row47_col2\" class=\"data row47 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row47_col3\" class=\"data row47 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row47_col4\" class=\"data row47 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row47_col5\" class=\"data row47 col5\" >transformer.h.3.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_d5b4c_row48_col0\" class=\"data row48 col0\" >decoder_blocks.3.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row48_col1\" class=\"data row48 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row48_col2\" class=\"data row48 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row48_col3\" class=\"data row48 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row48_col4\" class=\"data row48 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row48_col5\" class=\"data row48 col5\" >transformer.h.3.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_d5b4c_row49_col0\" class=\"data row49 col0\" >decoder_blocks.3.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row49_col1\" class=\"data row49 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row49_col2\" class=\"data row49 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row49_col3\" class=\"data row49 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row49_col4\" class=\"data row49 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row49_col5\" class=\"data row49 col5\" >transformer.h.3.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_d5b4c_row50_col0\" class=\"data row50 col0\" >decoder_blocks.4.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row50_col1\" class=\"data row50 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row50_col2\" class=\"data row50 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row50_col3\" class=\"data row50 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row50_col4\" class=\"data row50 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row50_col5\" class=\"data row50 col5\" >transformer.h.4.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_d5b4c_row51_col0\" class=\"data row51 col0\" >decoder_blocks.4.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row51_col1\" class=\"data row51 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row51_col2\" class=\"data row51 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row51_col3\" class=\"data row51 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row51_col4\" class=\"data row51 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row51_col5\" class=\"data row51 col5\" >transformer.h.4.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_d5b4c_row52_col0\" class=\"data row52 col0\" >decoder_blocks.4.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row52_col1\" class=\"data row52 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row52_col2\" class=\"data row52 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row52_col3\" class=\"data row52 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row52_col4\" class=\"data row52 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row52_col5\" class=\"data row52 col5\" >transformer.h.4.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_d5b4c_row53_col0\" class=\"data row53 col0\" >decoder_blocks.4.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row53_col1\" class=\"data row53 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row53_col2\" class=\"data row53 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row53_col3\" class=\"data row53 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row53_col4\" class=\"data row53 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row53_col5\" class=\"data row53 col5\" >transformer.h.4.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_d5b4c_row54_col0\" class=\"data row54 col0\" >decoder_blocks.4.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row54_col1\" class=\"data row54 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row54_col2\" class=\"data row54 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row54_col3\" class=\"data row54 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row54_col4\" class=\"data row54 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row54_col5\" class=\"data row54 col5\" >transformer.h.4.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_d5b4c_row55_col0\" class=\"data row55 col0\" >decoder_blocks.4.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row55_col1\" class=\"data row55 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row55_col2\" class=\"data row55 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row55_col3\" class=\"data row55 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row55_col4\" class=\"data row55 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row55_col5\" class=\"data row55 col5\" >transformer.h.4.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_d5b4c_row56_col0\" class=\"data row56 col0\" >decoder_blocks.4.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row56_col1\" class=\"data row56 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row56_col2\" class=\"data row56 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row56_col3\" class=\"data row56 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row56_col4\" class=\"data row56 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row56_col5\" class=\"data row56 col5\" >transformer.h.4.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_d5b4c_row57_col0\" class=\"data row57 col0\" >decoder_blocks.4.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row57_col1\" class=\"data row57 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row57_col2\" class=\"data row57 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row57_col3\" class=\"data row57 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row57_col4\" class=\"data row57 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row57_col5\" class=\"data row57 col5\" >transformer.h.4.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_d5b4c_row58_col0\" class=\"data row58 col0\" >decoder_blocks.4.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row58_col1\" class=\"data row58 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row58_col2\" class=\"data row58 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row58_col3\" class=\"data row58 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row58_col4\" class=\"data row58 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row58_col5\" class=\"data row58 col5\" >transformer.h.4.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_d5b4c_row59_col0\" class=\"data row59 col0\" >decoder_blocks.4.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row59_col1\" class=\"data row59 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row59_col2\" class=\"data row59 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row59_col3\" class=\"data row59 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row59_col4\" class=\"data row59 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row59_col5\" class=\"data row59 col5\" >transformer.h.4.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "      <td id=\"T_d5b4c_row60_col0\" class=\"data row60 col0\" >decoder_blocks.4.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row60_col1\" class=\"data row60 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row60_col2\" class=\"data row60 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row60_col3\" class=\"data row60 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row60_col4\" class=\"data row60 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row60_col5\" class=\"data row60 col5\" >transformer.h.4.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "      <td id=\"T_d5b4c_row61_col0\" class=\"data row61 col0\" >decoder_blocks.4.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row61_col1\" class=\"data row61 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row61_col2\" class=\"data row61 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row61_col3\" class=\"data row61 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row61_col4\" class=\"data row61 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row61_col5\" class=\"data row61 col5\" >transformer.h.4.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "      <td id=\"T_d5b4c_row62_col0\" class=\"data row62 col0\" >decoder_blocks.5.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row62_col1\" class=\"data row62 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row62_col2\" class=\"data row62 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row62_col3\" class=\"data row62 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row62_col4\" class=\"data row62 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row62_col5\" class=\"data row62 col5\" >transformer.h.5.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
       "      <td id=\"T_d5b4c_row63_col0\" class=\"data row63 col0\" >decoder_blocks.5.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row63_col1\" class=\"data row63 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row63_col2\" class=\"data row63 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row63_col3\" class=\"data row63 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row63_col4\" class=\"data row63 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row63_col5\" class=\"data row63 col5\" >transformer.h.5.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
       "      <td id=\"T_d5b4c_row64_col0\" class=\"data row64 col0\" >decoder_blocks.5.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row64_col1\" class=\"data row64 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row64_col2\" class=\"data row64 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row64_col3\" class=\"data row64 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row64_col4\" class=\"data row64 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row64_col5\" class=\"data row64 col5\" >transformer.h.5.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row65\" class=\"row_heading level0 row65\" >65</th>\n",
       "      <td id=\"T_d5b4c_row65_col0\" class=\"data row65 col0\" >decoder_blocks.5.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row65_col1\" class=\"data row65 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row65_col2\" class=\"data row65 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row65_col3\" class=\"data row65 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row65_col4\" class=\"data row65 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row65_col5\" class=\"data row65 col5\" >transformer.h.5.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row66\" class=\"row_heading level0 row66\" >66</th>\n",
       "      <td id=\"T_d5b4c_row66_col0\" class=\"data row66 col0\" >decoder_blocks.5.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row66_col1\" class=\"data row66 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row66_col2\" class=\"data row66 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row66_col3\" class=\"data row66 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row66_col4\" class=\"data row66 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row66_col5\" class=\"data row66 col5\" >transformer.h.5.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row67\" class=\"row_heading level0 row67\" >67</th>\n",
       "      <td id=\"T_d5b4c_row67_col0\" class=\"data row67 col0\" >decoder_blocks.5.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row67_col1\" class=\"data row67 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row67_col2\" class=\"data row67 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row67_col3\" class=\"data row67 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row67_col4\" class=\"data row67 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row67_col5\" class=\"data row67 col5\" >transformer.h.5.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row68\" class=\"row_heading level0 row68\" >68</th>\n",
       "      <td id=\"T_d5b4c_row68_col0\" class=\"data row68 col0\" >decoder_blocks.5.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row68_col1\" class=\"data row68 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row68_col2\" class=\"data row68 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row68_col3\" class=\"data row68 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row68_col4\" class=\"data row68 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row68_col5\" class=\"data row68 col5\" >transformer.h.5.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row69\" class=\"row_heading level0 row69\" >69</th>\n",
       "      <td id=\"T_d5b4c_row69_col0\" class=\"data row69 col0\" >decoder_blocks.5.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row69_col1\" class=\"data row69 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row69_col2\" class=\"data row69 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row69_col3\" class=\"data row69 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row69_col4\" class=\"data row69 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row69_col5\" class=\"data row69 col5\" >transformer.h.5.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row70\" class=\"row_heading level0 row70\" >70</th>\n",
       "      <td id=\"T_d5b4c_row70_col0\" class=\"data row70 col0\" >decoder_blocks.5.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row70_col1\" class=\"data row70 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row70_col2\" class=\"data row70 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row70_col3\" class=\"data row70 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row70_col4\" class=\"data row70 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row70_col5\" class=\"data row70 col5\" >transformer.h.5.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row71\" class=\"row_heading level0 row71\" >71</th>\n",
       "      <td id=\"T_d5b4c_row71_col0\" class=\"data row71 col0\" >decoder_blocks.5.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row71_col1\" class=\"data row71 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row71_col2\" class=\"data row71 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row71_col3\" class=\"data row71 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row71_col4\" class=\"data row71 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row71_col5\" class=\"data row71 col5\" >transformer.h.5.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row72\" class=\"row_heading level0 row72\" >72</th>\n",
       "      <td id=\"T_d5b4c_row72_col0\" class=\"data row72 col0\" >decoder_blocks.5.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row72_col1\" class=\"data row72 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row72_col2\" class=\"data row72 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row72_col3\" class=\"data row72 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row72_col4\" class=\"data row72 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row72_col5\" class=\"data row72 col5\" >transformer.h.5.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row73\" class=\"row_heading level0 row73\" >73</th>\n",
       "      <td id=\"T_d5b4c_row73_col0\" class=\"data row73 col0\" >decoder_blocks.5.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row73_col1\" class=\"data row73 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row73_col2\" class=\"data row73 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row73_col3\" class=\"data row73 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row73_col4\" class=\"data row73 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row73_col5\" class=\"data row73 col5\" >transformer.h.5.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row74\" class=\"row_heading level0 row74\" >74</th>\n",
       "      <td id=\"T_d5b4c_row74_col0\" class=\"data row74 col0\" >decoder_blocks.6.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row74_col1\" class=\"data row74 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row74_col2\" class=\"data row74 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row74_col3\" class=\"data row74 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row74_col4\" class=\"data row74 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row74_col5\" class=\"data row74 col5\" >transformer.h.6.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row75\" class=\"row_heading level0 row75\" >75</th>\n",
       "      <td id=\"T_d5b4c_row75_col0\" class=\"data row75 col0\" >decoder_blocks.6.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row75_col1\" class=\"data row75 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row75_col2\" class=\"data row75 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row75_col3\" class=\"data row75 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row75_col4\" class=\"data row75 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row75_col5\" class=\"data row75 col5\" >transformer.h.6.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row76\" class=\"row_heading level0 row76\" >76</th>\n",
       "      <td id=\"T_d5b4c_row76_col0\" class=\"data row76 col0\" >decoder_blocks.6.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row76_col1\" class=\"data row76 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row76_col2\" class=\"data row76 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row76_col3\" class=\"data row76 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row76_col4\" class=\"data row76 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row76_col5\" class=\"data row76 col5\" >transformer.h.6.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row77\" class=\"row_heading level0 row77\" >77</th>\n",
       "      <td id=\"T_d5b4c_row77_col0\" class=\"data row77 col0\" >decoder_blocks.6.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row77_col1\" class=\"data row77 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row77_col2\" class=\"data row77 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row77_col3\" class=\"data row77 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row77_col4\" class=\"data row77 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row77_col5\" class=\"data row77 col5\" >transformer.h.6.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row78\" class=\"row_heading level0 row78\" >78</th>\n",
       "      <td id=\"T_d5b4c_row78_col0\" class=\"data row78 col0\" >decoder_blocks.6.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row78_col1\" class=\"data row78 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row78_col2\" class=\"data row78 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row78_col3\" class=\"data row78 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row78_col4\" class=\"data row78 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row78_col5\" class=\"data row78 col5\" >transformer.h.6.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row79\" class=\"row_heading level0 row79\" >79</th>\n",
       "      <td id=\"T_d5b4c_row79_col0\" class=\"data row79 col0\" >decoder_blocks.6.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row79_col1\" class=\"data row79 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row79_col2\" class=\"data row79 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row79_col3\" class=\"data row79 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row79_col4\" class=\"data row79 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row79_col5\" class=\"data row79 col5\" >transformer.h.6.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row80\" class=\"row_heading level0 row80\" >80</th>\n",
       "      <td id=\"T_d5b4c_row80_col0\" class=\"data row80 col0\" >decoder_blocks.6.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row80_col1\" class=\"data row80 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row80_col2\" class=\"data row80 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row80_col3\" class=\"data row80 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row80_col4\" class=\"data row80 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row80_col5\" class=\"data row80 col5\" >transformer.h.6.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row81\" class=\"row_heading level0 row81\" >81</th>\n",
       "      <td id=\"T_d5b4c_row81_col0\" class=\"data row81 col0\" >decoder_blocks.6.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row81_col1\" class=\"data row81 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row81_col2\" class=\"data row81 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row81_col3\" class=\"data row81 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row81_col4\" class=\"data row81 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row81_col5\" class=\"data row81 col5\" >transformer.h.6.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row82\" class=\"row_heading level0 row82\" >82</th>\n",
       "      <td id=\"T_d5b4c_row82_col0\" class=\"data row82 col0\" >decoder_blocks.6.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row82_col1\" class=\"data row82 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row82_col2\" class=\"data row82 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row82_col3\" class=\"data row82 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row82_col4\" class=\"data row82 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row82_col5\" class=\"data row82 col5\" >transformer.h.6.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row83\" class=\"row_heading level0 row83\" >83</th>\n",
       "      <td id=\"T_d5b4c_row83_col0\" class=\"data row83 col0\" >decoder_blocks.6.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row83_col1\" class=\"data row83 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row83_col2\" class=\"data row83 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row83_col3\" class=\"data row83 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row83_col4\" class=\"data row83 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row83_col5\" class=\"data row83 col5\" >transformer.h.6.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row84\" class=\"row_heading level0 row84\" >84</th>\n",
       "      <td id=\"T_d5b4c_row84_col0\" class=\"data row84 col0\" >decoder_blocks.6.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row84_col1\" class=\"data row84 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row84_col2\" class=\"data row84 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row84_col3\" class=\"data row84 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row84_col4\" class=\"data row84 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row84_col5\" class=\"data row84 col5\" >transformer.h.6.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row85\" class=\"row_heading level0 row85\" >85</th>\n",
       "      <td id=\"T_d5b4c_row85_col0\" class=\"data row85 col0\" >decoder_blocks.6.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row85_col1\" class=\"data row85 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row85_col2\" class=\"data row85 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row85_col3\" class=\"data row85 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row85_col4\" class=\"data row85 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row85_col5\" class=\"data row85 col5\" >transformer.h.6.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row86\" class=\"row_heading level0 row86\" >86</th>\n",
       "      <td id=\"T_d5b4c_row86_col0\" class=\"data row86 col0\" >decoder_blocks.7.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row86_col1\" class=\"data row86 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row86_col2\" class=\"data row86 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row86_col3\" class=\"data row86 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row86_col4\" class=\"data row86 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row86_col5\" class=\"data row86 col5\" >transformer.h.7.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row87\" class=\"row_heading level0 row87\" >87</th>\n",
       "      <td id=\"T_d5b4c_row87_col0\" class=\"data row87 col0\" >decoder_blocks.7.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row87_col1\" class=\"data row87 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row87_col2\" class=\"data row87 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row87_col3\" class=\"data row87 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row87_col4\" class=\"data row87 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row87_col5\" class=\"data row87 col5\" >transformer.h.7.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row88\" class=\"row_heading level0 row88\" >88</th>\n",
       "      <td id=\"T_d5b4c_row88_col0\" class=\"data row88 col0\" >decoder_blocks.7.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row88_col1\" class=\"data row88 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row88_col2\" class=\"data row88 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row88_col3\" class=\"data row88 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row88_col4\" class=\"data row88 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row88_col5\" class=\"data row88 col5\" >transformer.h.7.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row89\" class=\"row_heading level0 row89\" >89</th>\n",
       "      <td id=\"T_d5b4c_row89_col0\" class=\"data row89 col0\" >decoder_blocks.7.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row89_col1\" class=\"data row89 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row89_col2\" class=\"data row89 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row89_col3\" class=\"data row89 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row89_col4\" class=\"data row89 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row89_col5\" class=\"data row89 col5\" >transformer.h.7.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row90\" class=\"row_heading level0 row90\" >90</th>\n",
       "      <td id=\"T_d5b4c_row90_col0\" class=\"data row90 col0\" >decoder_blocks.7.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row90_col1\" class=\"data row90 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row90_col2\" class=\"data row90 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row90_col3\" class=\"data row90 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row90_col4\" class=\"data row90 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row90_col5\" class=\"data row90 col5\" >transformer.h.7.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row91\" class=\"row_heading level0 row91\" >91</th>\n",
       "      <td id=\"T_d5b4c_row91_col0\" class=\"data row91 col0\" >decoder_blocks.7.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row91_col1\" class=\"data row91 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row91_col2\" class=\"data row91 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row91_col3\" class=\"data row91 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row91_col4\" class=\"data row91 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row91_col5\" class=\"data row91 col5\" >transformer.h.7.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row92\" class=\"row_heading level0 row92\" >92</th>\n",
       "      <td id=\"T_d5b4c_row92_col0\" class=\"data row92 col0\" >decoder_blocks.7.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row92_col1\" class=\"data row92 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row92_col2\" class=\"data row92 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row92_col3\" class=\"data row92 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row92_col4\" class=\"data row92 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row92_col5\" class=\"data row92 col5\" >transformer.h.7.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row93\" class=\"row_heading level0 row93\" >93</th>\n",
       "      <td id=\"T_d5b4c_row93_col0\" class=\"data row93 col0\" >decoder_blocks.7.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row93_col1\" class=\"data row93 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row93_col2\" class=\"data row93 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row93_col3\" class=\"data row93 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row93_col4\" class=\"data row93 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row93_col5\" class=\"data row93 col5\" >transformer.h.7.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row94\" class=\"row_heading level0 row94\" >94</th>\n",
       "      <td id=\"T_d5b4c_row94_col0\" class=\"data row94 col0\" >decoder_blocks.7.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row94_col1\" class=\"data row94 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row94_col2\" class=\"data row94 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row94_col3\" class=\"data row94 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row94_col4\" class=\"data row94 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row94_col5\" class=\"data row94 col5\" >transformer.h.7.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row95\" class=\"row_heading level0 row95\" >95</th>\n",
       "      <td id=\"T_d5b4c_row95_col0\" class=\"data row95 col0\" >decoder_blocks.7.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row95_col1\" class=\"data row95 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row95_col2\" class=\"data row95 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row95_col3\" class=\"data row95 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row95_col4\" class=\"data row95 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row95_col5\" class=\"data row95 col5\" >transformer.h.7.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row96\" class=\"row_heading level0 row96\" >96</th>\n",
       "      <td id=\"T_d5b4c_row96_col0\" class=\"data row96 col0\" >decoder_blocks.7.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row96_col1\" class=\"data row96 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row96_col2\" class=\"data row96 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row96_col3\" class=\"data row96 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row96_col4\" class=\"data row96 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row96_col5\" class=\"data row96 col5\" >transformer.h.7.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row97\" class=\"row_heading level0 row97\" >97</th>\n",
       "      <td id=\"T_d5b4c_row97_col0\" class=\"data row97 col0\" >decoder_blocks.7.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row97_col1\" class=\"data row97 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row97_col2\" class=\"data row97 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row97_col3\" class=\"data row97 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row97_col4\" class=\"data row97 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row97_col5\" class=\"data row97 col5\" >transformer.h.7.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row98\" class=\"row_heading level0 row98\" >98</th>\n",
       "      <td id=\"T_d5b4c_row98_col0\" class=\"data row98 col0\" >decoder_blocks.8.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row98_col1\" class=\"data row98 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row98_col2\" class=\"data row98 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row98_col3\" class=\"data row98 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row98_col4\" class=\"data row98 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row98_col5\" class=\"data row98 col5\" >transformer.h.8.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row99\" class=\"row_heading level0 row99\" >99</th>\n",
       "      <td id=\"T_d5b4c_row99_col0\" class=\"data row99 col0\" >decoder_blocks.8.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row99_col1\" class=\"data row99 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row99_col2\" class=\"data row99 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row99_col3\" class=\"data row99 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row99_col4\" class=\"data row99 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row99_col5\" class=\"data row99 col5\" >transformer.h.8.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row100\" class=\"row_heading level0 row100\" >100</th>\n",
       "      <td id=\"T_d5b4c_row100_col0\" class=\"data row100 col0\" >decoder_blocks.8.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row100_col1\" class=\"data row100 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row100_col2\" class=\"data row100 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row100_col3\" class=\"data row100 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row100_col4\" class=\"data row100 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row100_col5\" class=\"data row100 col5\" >transformer.h.8.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row101\" class=\"row_heading level0 row101\" >101</th>\n",
       "      <td id=\"T_d5b4c_row101_col0\" class=\"data row101 col0\" >decoder_blocks.8.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row101_col1\" class=\"data row101 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row101_col2\" class=\"data row101 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row101_col3\" class=\"data row101 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row101_col4\" class=\"data row101 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row101_col5\" class=\"data row101 col5\" >transformer.h.8.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row102\" class=\"row_heading level0 row102\" >102</th>\n",
       "      <td id=\"T_d5b4c_row102_col0\" class=\"data row102 col0\" >decoder_blocks.8.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row102_col1\" class=\"data row102 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row102_col2\" class=\"data row102 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row102_col3\" class=\"data row102 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row102_col4\" class=\"data row102 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row102_col5\" class=\"data row102 col5\" >transformer.h.8.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row103\" class=\"row_heading level0 row103\" >103</th>\n",
       "      <td id=\"T_d5b4c_row103_col0\" class=\"data row103 col0\" >decoder_blocks.8.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row103_col1\" class=\"data row103 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row103_col2\" class=\"data row103 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row103_col3\" class=\"data row103 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row103_col4\" class=\"data row103 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row103_col5\" class=\"data row103 col5\" >transformer.h.8.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row104\" class=\"row_heading level0 row104\" >104</th>\n",
       "      <td id=\"T_d5b4c_row104_col0\" class=\"data row104 col0\" >decoder_blocks.8.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row104_col1\" class=\"data row104 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row104_col2\" class=\"data row104 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row104_col3\" class=\"data row104 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row104_col4\" class=\"data row104 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row104_col5\" class=\"data row104 col5\" >transformer.h.8.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row105\" class=\"row_heading level0 row105\" >105</th>\n",
       "      <td id=\"T_d5b4c_row105_col0\" class=\"data row105 col0\" >decoder_blocks.8.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row105_col1\" class=\"data row105 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row105_col2\" class=\"data row105 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row105_col3\" class=\"data row105 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row105_col4\" class=\"data row105 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row105_col5\" class=\"data row105 col5\" >transformer.h.8.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row106\" class=\"row_heading level0 row106\" >106</th>\n",
       "      <td id=\"T_d5b4c_row106_col0\" class=\"data row106 col0\" >decoder_blocks.8.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row106_col1\" class=\"data row106 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row106_col2\" class=\"data row106 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row106_col3\" class=\"data row106 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row106_col4\" class=\"data row106 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row106_col5\" class=\"data row106 col5\" >transformer.h.8.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row107\" class=\"row_heading level0 row107\" >107</th>\n",
       "      <td id=\"T_d5b4c_row107_col0\" class=\"data row107 col0\" >decoder_blocks.8.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row107_col1\" class=\"data row107 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row107_col2\" class=\"data row107 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row107_col3\" class=\"data row107 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row107_col4\" class=\"data row107 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row107_col5\" class=\"data row107 col5\" >transformer.h.8.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row108\" class=\"row_heading level0 row108\" >108</th>\n",
       "      <td id=\"T_d5b4c_row108_col0\" class=\"data row108 col0\" >decoder_blocks.8.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row108_col1\" class=\"data row108 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row108_col2\" class=\"data row108 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row108_col3\" class=\"data row108 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row108_col4\" class=\"data row108 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row108_col5\" class=\"data row108 col5\" >transformer.h.8.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row109\" class=\"row_heading level0 row109\" >109</th>\n",
       "      <td id=\"T_d5b4c_row109_col0\" class=\"data row109 col0\" >decoder_blocks.8.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row109_col1\" class=\"data row109 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row109_col2\" class=\"data row109 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row109_col3\" class=\"data row109 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row109_col4\" class=\"data row109 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row109_col5\" class=\"data row109 col5\" >transformer.h.8.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row110\" class=\"row_heading level0 row110\" >110</th>\n",
       "      <td id=\"T_d5b4c_row110_col0\" class=\"data row110 col0\" >decoder_blocks.9.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row110_col1\" class=\"data row110 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row110_col2\" class=\"data row110 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row110_col3\" class=\"data row110 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row110_col4\" class=\"data row110 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row110_col5\" class=\"data row110 col5\" >transformer.h.9.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row111\" class=\"row_heading level0 row111\" >111</th>\n",
       "      <td id=\"T_d5b4c_row111_col0\" class=\"data row111 col0\" >decoder_blocks.9.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row111_col1\" class=\"data row111 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row111_col2\" class=\"data row111 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row111_col3\" class=\"data row111 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row111_col4\" class=\"data row111 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row111_col5\" class=\"data row111 col5\" >transformer.h.9.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row112\" class=\"row_heading level0 row112\" >112</th>\n",
       "      <td id=\"T_d5b4c_row112_col0\" class=\"data row112 col0\" >decoder_blocks.9.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row112_col1\" class=\"data row112 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row112_col2\" class=\"data row112 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row112_col3\" class=\"data row112 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row112_col4\" class=\"data row112 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row112_col5\" class=\"data row112 col5\" >transformer.h.9.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row113\" class=\"row_heading level0 row113\" >113</th>\n",
       "      <td id=\"T_d5b4c_row113_col0\" class=\"data row113 col0\" >decoder_blocks.9.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row113_col1\" class=\"data row113 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row113_col2\" class=\"data row113 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row113_col3\" class=\"data row113 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row113_col4\" class=\"data row113 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row113_col5\" class=\"data row113 col5\" >transformer.h.9.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row114\" class=\"row_heading level0 row114\" >114</th>\n",
       "      <td id=\"T_d5b4c_row114_col0\" class=\"data row114 col0\" >decoder_blocks.9.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row114_col1\" class=\"data row114 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row114_col2\" class=\"data row114 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row114_col3\" class=\"data row114 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row114_col4\" class=\"data row114 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row114_col5\" class=\"data row114 col5\" >transformer.h.9.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row115\" class=\"row_heading level0 row115\" >115</th>\n",
       "      <td id=\"T_d5b4c_row115_col0\" class=\"data row115 col0\" >decoder_blocks.9.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row115_col1\" class=\"data row115 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row115_col2\" class=\"data row115 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row115_col3\" class=\"data row115 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row115_col4\" class=\"data row115 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row115_col5\" class=\"data row115 col5\" >transformer.h.9.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row116\" class=\"row_heading level0 row116\" >116</th>\n",
       "      <td id=\"T_d5b4c_row116_col0\" class=\"data row116 col0\" >decoder_blocks.9.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row116_col1\" class=\"data row116 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row116_col2\" class=\"data row116 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row116_col3\" class=\"data row116 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row116_col4\" class=\"data row116 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row116_col5\" class=\"data row116 col5\" >transformer.h.9.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row117\" class=\"row_heading level0 row117\" >117</th>\n",
       "      <td id=\"T_d5b4c_row117_col0\" class=\"data row117 col0\" >decoder_blocks.9.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row117_col1\" class=\"data row117 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row117_col2\" class=\"data row117 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row117_col3\" class=\"data row117 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row117_col4\" class=\"data row117 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row117_col5\" class=\"data row117 col5\" >transformer.h.9.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row118\" class=\"row_heading level0 row118\" >118</th>\n",
       "      <td id=\"T_d5b4c_row118_col0\" class=\"data row118 col0\" >decoder_blocks.9.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row118_col1\" class=\"data row118 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row118_col2\" class=\"data row118 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row118_col3\" class=\"data row118 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row118_col4\" class=\"data row118 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row118_col5\" class=\"data row118 col5\" >transformer.h.9.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row119\" class=\"row_heading level0 row119\" >119</th>\n",
       "      <td id=\"T_d5b4c_row119_col0\" class=\"data row119 col0\" >decoder_blocks.9.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row119_col1\" class=\"data row119 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row119_col2\" class=\"data row119 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row119_col3\" class=\"data row119 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row119_col4\" class=\"data row119 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row119_col5\" class=\"data row119 col5\" >transformer.h.9.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row120\" class=\"row_heading level0 row120\" >120</th>\n",
       "      <td id=\"T_d5b4c_row120_col0\" class=\"data row120 col0\" >decoder_blocks.9.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row120_col1\" class=\"data row120 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row120_col2\" class=\"data row120 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row120_col3\" class=\"data row120 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row120_col4\" class=\"data row120 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row120_col5\" class=\"data row120 col5\" >transformer.h.9.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row121\" class=\"row_heading level0 row121\" >121</th>\n",
       "      <td id=\"T_d5b4c_row121_col0\" class=\"data row121 col0\" >decoder_blocks.9.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row121_col1\" class=\"data row121 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row121_col2\" class=\"data row121 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row121_col3\" class=\"data row121 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row121_col4\" class=\"data row121 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row121_col5\" class=\"data row121 col5\" >transformer.h.9.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row122\" class=\"row_heading level0 row122\" >122</th>\n",
       "      <td id=\"T_d5b4c_row122_col0\" class=\"data row122 col0\" >decoder_blocks.10.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row122_col1\" class=\"data row122 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row122_col2\" class=\"data row122 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row122_col3\" class=\"data row122 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row122_col4\" class=\"data row122 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row122_col5\" class=\"data row122 col5\" >transformer.h.10.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row123\" class=\"row_heading level0 row123\" >123</th>\n",
       "      <td id=\"T_d5b4c_row123_col0\" class=\"data row123 col0\" >decoder_blocks.10.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row123_col1\" class=\"data row123 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row123_col2\" class=\"data row123 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row123_col3\" class=\"data row123 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row123_col4\" class=\"data row123 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row123_col5\" class=\"data row123 col5\" >transformer.h.10.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row124\" class=\"row_heading level0 row124\" >124</th>\n",
       "      <td id=\"T_d5b4c_row124_col0\" class=\"data row124 col0\" >decoder_blocks.10.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row124_col1\" class=\"data row124 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row124_col2\" class=\"data row124 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row124_col3\" class=\"data row124 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row124_col4\" class=\"data row124 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row124_col5\" class=\"data row124 col5\" >transformer.h.10.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row125\" class=\"row_heading level0 row125\" >125</th>\n",
       "      <td id=\"T_d5b4c_row125_col0\" class=\"data row125 col0\" >decoder_blocks.10.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row125_col1\" class=\"data row125 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row125_col2\" class=\"data row125 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row125_col3\" class=\"data row125 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row125_col4\" class=\"data row125 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row125_col5\" class=\"data row125 col5\" >transformer.h.10.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row126\" class=\"row_heading level0 row126\" >126</th>\n",
       "      <td id=\"T_d5b4c_row126_col0\" class=\"data row126 col0\" >decoder_blocks.10.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row126_col1\" class=\"data row126 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row126_col2\" class=\"data row126 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row126_col3\" class=\"data row126 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row126_col4\" class=\"data row126 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row126_col5\" class=\"data row126 col5\" >transformer.h.10.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row127\" class=\"row_heading level0 row127\" >127</th>\n",
       "      <td id=\"T_d5b4c_row127_col0\" class=\"data row127 col0\" >decoder_blocks.10.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row127_col1\" class=\"data row127 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row127_col2\" class=\"data row127 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row127_col3\" class=\"data row127 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row127_col4\" class=\"data row127 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row127_col5\" class=\"data row127 col5\" >transformer.h.10.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row128\" class=\"row_heading level0 row128\" >128</th>\n",
       "      <td id=\"T_d5b4c_row128_col0\" class=\"data row128 col0\" >decoder_blocks.10.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row128_col1\" class=\"data row128 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row128_col2\" class=\"data row128 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row128_col3\" class=\"data row128 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row128_col4\" class=\"data row128 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row128_col5\" class=\"data row128 col5\" >transformer.h.10.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row129\" class=\"row_heading level0 row129\" >129</th>\n",
       "      <td id=\"T_d5b4c_row129_col0\" class=\"data row129 col0\" >decoder_blocks.10.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row129_col1\" class=\"data row129 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row129_col2\" class=\"data row129 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row129_col3\" class=\"data row129 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row129_col4\" class=\"data row129 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row129_col5\" class=\"data row129 col5\" >transformer.h.10.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row130\" class=\"row_heading level0 row130\" >130</th>\n",
       "      <td id=\"T_d5b4c_row130_col0\" class=\"data row130 col0\" >decoder_blocks.10.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row130_col1\" class=\"data row130 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row130_col2\" class=\"data row130 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row130_col3\" class=\"data row130 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row130_col4\" class=\"data row130 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row130_col5\" class=\"data row130 col5\" >transformer.h.10.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row131\" class=\"row_heading level0 row131\" >131</th>\n",
       "      <td id=\"T_d5b4c_row131_col0\" class=\"data row131 col0\" >decoder_blocks.10.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row131_col1\" class=\"data row131 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row131_col2\" class=\"data row131 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row131_col3\" class=\"data row131 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row131_col4\" class=\"data row131 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row131_col5\" class=\"data row131 col5\" >transformer.h.10.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row132\" class=\"row_heading level0 row132\" >132</th>\n",
       "      <td id=\"T_d5b4c_row132_col0\" class=\"data row132 col0\" >decoder_blocks.10.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row132_col1\" class=\"data row132 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row132_col2\" class=\"data row132 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row132_col3\" class=\"data row132 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row132_col4\" class=\"data row132 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row132_col5\" class=\"data row132 col5\" >transformer.h.10.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row133\" class=\"row_heading level0 row133\" >133</th>\n",
       "      <td id=\"T_d5b4c_row133_col0\" class=\"data row133 col0\" >decoder_blocks.10.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row133_col1\" class=\"data row133 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row133_col2\" class=\"data row133 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row133_col3\" class=\"data row133 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row133_col4\" class=\"data row133 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row133_col5\" class=\"data row133 col5\" >transformer.h.10.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row134\" class=\"row_heading level0 row134\" >134</th>\n",
       "      <td id=\"T_d5b4c_row134_col0\" class=\"data row134 col0\" >decoder_blocks.11.ln1.weight</td>\n",
       "      <td id=\"T_d5b4c_row134_col1\" class=\"data row134 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row134_col2\" class=\"data row134 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row134_col3\" class=\"data row134 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row134_col4\" class=\"data row134 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row134_col5\" class=\"data row134 col5\" >transformer.h.11.ln_1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row135\" class=\"row_heading level0 row135\" >135</th>\n",
       "      <td id=\"T_d5b4c_row135_col0\" class=\"data row135 col0\" >decoder_blocks.11.ln1.bias</td>\n",
       "      <td id=\"T_d5b4c_row135_col1\" class=\"data row135 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row135_col2\" class=\"data row135 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row135_col3\" class=\"data row135 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row135_col4\" class=\"data row135 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row135_col5\" class=\"data row135 col5\" >transformer.h.11.ln_1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row136\" class=\"row_heading level0 row136\" >136</th>\n",
       "      <td id=\"T_d5b4c_row136_col0\" class=\"data row136 col0\" >decoder_blocks.11.attn.W_QKV.weight</td>\n",
       "      <td id=\"T_d5b4c_row136_col1\" class=\"data row136 col1\" >(2304, 768)</td>\n",
       "      <td id=\"T_d5b4c_row136_col2\" class=\"data row136 col2\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row136_col3\" class=\"data row136 col3\" >1769472</td>\n",
       "      <td id=\"T_d5b4c_row136_col4\" class=\"data row136 col4\" >(768, 2304)</td>\n",
       "      <td id=\"T_d5b4c_row136_col5\" class=\"data row136 col5\" >transformer.h.11.attn.c_attn.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row137\" class=\"row_heading level0 row137\" >137</th>\n",
       "      <td id=\"T_d5b4c_row137_col0\" class=\"data row137 col0\" >decoder_blocks.11.attn.W_QKV.bias</td>\n",
       "      <td id=\"T_d5b4c_row137_col1\" class=\"data row137 col1\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row137_col2\" class=\"data row137 col2\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row137_col3\" class=\"data row137 col3\" >2304</td>\n",
       "      <td id=\"T_d5b4c_row137_col4\" class=\"data row137 col4\" >(2304,)</td>\n",
       "      <td id=\"T_d5b4c_row137_col5\" class=\"data row137 col5\" >transformer.h.11.attn.c_attn.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row138\" class=\"row_heading level0 row138\" >138</th>\n",
       "      <td id=\"T_d5b4c_row138_col0\" class=\"data row138 col0\" >decoder_blocks.11.attn.W_O.weight</td>\n",
       "      <td id=\"T_d5b4c_row138_col1\" class=\"data row138 col1\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row138_col2\" class=\"data row138 col2\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row138_col3\" class=\"data row138 col3\" >589824</td>\n",
       "      <td id=\"T_d5b4c_row138_col4\" class=\"data row138 col4\" >(768, 768)</td>\n",
       "      <td id=\"T_d5b4c_row138_col5\" class=\"data row138 col5\" >transformer.h.11.attn.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row139\" class=\"row_heading level0 row139\" >139</th>\n",
       "      <td id=\"T_d5b4c_row139_col0\" class=\"data row139 col0\" >decoder_blocks.11.attn.W_O.bias</td>\n",
       "      <td id=\"T_d5b4c_row139_col1\" class=\"data row139 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row139_col2\" class=\"data row139 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row139_col3\" class=\"data row139 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row139_col4\" class=\"data row139 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row139_col5\" class=\"data row139 col5\" >transformer.h.11.attn.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row140\" class=\"row_heading level0 row140\" >140</th>\n",
       "      <td id=\"T_d5b4c_row140_col0\" class=\"data row140 col0\" >decoder_blocks.11.ln2.weight</td>\n",
       "      <td id=\"T_d5b4c_row140_col1\" class=\"data row140 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row140_col2\" class=\"data row140 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row140_col3\" class=\"data row140 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row140_col4\" class=\"data row140 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row140_col5\" class=\"data row140 col5\" >transformer.h.11.ln_2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row141\" class=\"row_heading level0 row141\" >141</th>\n",
       "      <td id=\"T_d5b4c_row141_col0\" class=\"data row141 col0\" >decoder_blocks.11.ln2.bias</td>\n",
       "      <td id=\"T_d5b4c_row141_col1\" class=\"data row141 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row141_col2\" class=\"data row141 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row141_col3\" class=\"data row141 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row141_col4\" class=\"data row141 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row141_col5\" class=\"data row141 col5\" >transformer.h.11.ln_2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row142\" class=\"row_heading level0 row142\" >142</th>\n",
       "      <td id=\"T_d5b4c_row142_col0\" class=\"data row142 col0\" >decoder_blocks.11.mlp.mlp_block.0.weight</td>\n",
       "      <td id=\"T_d5b4c_row142_col1\" class=\"data row142 col1\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row142_col2\" class=\"data row142 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row142_col3\" class=\"data row142 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row142_col4\" class=\"data row142 col4\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row142_col5\" class=\"data row142 col5\" >transformer.h.11.mlp.c_fc.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row143\" class=\"row_heading level0 row143\" >143</th>\n",
       "      <td id=\"T_d5b4c_row143_col0\" class=\"data row143 col0\" >decoder_blocks.11.mlp.mlp_block.0.bias</td>\n",
       "      <td id=\"T_d5b4c_row143_col1\" class=\"data row143 col1\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row143_col2\" class=\"data row143 col2\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row143_col3\" class=\"data row143 col3\" >3072</td>\n",
       "      <td id=\"T_d5b4c_row143_col4\" class=\"data row143 col4\" >(3072,)</td>\n",
       "      <td id=\"T_d5b4c_row143_col5\" class=\"data row143 col5\" >transformer.h.11.mlp.c_fc.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row144\" class=\"row_heading level0 row144\" >144</th>\n",
       "      <td id=\"T_d5b4c_row144_col0\" class=\"data row144 col0\" >decoder_blocks.11.mlp.mlp_block.2.weight</td>\n",
       "      <td id=\"T_d5b4c_row144_col1\" class=\"data row144 col1\" >(768, 3072)</td>\n",
       "      <td id=\"T_d5b4c_row144_col2\" class=\"data row144 col2\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row144_col3\" class=\"data row144 col3\" >2359296</td>\n",
       "      <td id=\"T_d5b4c_row144_col4\" class=\"data row144 col4\" >(3072, 768)</td>\n",
       "      <td id=\"T_d5b4c_row144_col5\" class=\"data row144 col5\" >transformer.h.11.mlp.c_proj.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row145\" class=\"row_heading level0 row145\" >145</th>\n",
       "      <td id=\"T_d5b4c_row145_col0\" class=\"data row145 col0\" >decoder_blocks.11.mlp.mlp_block.2.bias</td>\n",
       "      <td id=\"T_d5b4c_row145_col1\" class=\"data row145 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row145_col2\" class=\"data row145 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row145_col3\" class=\"data row145 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row145_col4\" class=\"data row145 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row145_col5\" class=\"data row145 col5\" >transformer.h.11.mlp.c_proj.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row146\" class=\"row_heading level0 row146\" >146</th>\n",
       "      <td id=\"T_d5b4c_row146_col0\" class=\"data row146 col0\" >final_layer_norm.weight</td>\n",
       "      <td id=\"T_d5b4c_row146_col1\" class=\"data row146 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row146_col2\" class=\"data row146 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row146_col3\" class=\"data row146 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row146_col4\" class=\"data row146 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row146_col5\" class=\"data row146 col5\" >transformer.ln_f.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b4c_level0_row147\" class=\"row_heading level0 row147\" >147</th>\n",
       "      <td id=\"T_d5b4c_row147_col0\" class=\"data row147 col0\" >final_layer_norm.bias</td>\n",
       "      <td id=\"T_d5b4c_row147_col1\" class=\"data row147 col1\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row147_col2\" class=\"data row147 col2\" >768</td>\n",
       "      <td id=\"T_d5b4c_row147_col3\" class=\"data row147 col3\" >768</td>\n",
       "      <td id=\"T_d5b4c_row147_col4\" class=\"data row147 col4\" >(768,)</td>\n",
       "      <td id=\"T_d5b4c_row147_col5\" class=\"data row147 col5\" >transformer.ln_f.bias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x165013070>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>their name</th>\n",
       "      <th>their shape</th>\n",
       "      <th>your name</th>\n",
       "      <th>your shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformer.wte.weight</td>\n",
       "      <td>(50257, 768)</td>\n",
       "      <td>text_embedding.weight</td>\n",
       "      <td>(50257, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformer.wpe.weight</td>\n",
       "      <td>(1024, 768)</td>\n",
       "      <td>position_embedding.weight</td>\n",
       "      <td>(1024, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformer.h.0.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.0.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformer.h.0.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.0.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformer.h.0.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.0.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>transformer.h.0.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.0.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>transformer.h.0.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.0.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transformer.h.0.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.0.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>transformer.h.0.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.0.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>transformer.h.0.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.0.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>transformer.h.0.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.0.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>transformer.h.0.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.0.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transformer.h.0.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.0.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transformer.h.0.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.0.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>transformer.h.1.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.1.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>transformer.h.1.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.1.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>transformer.h.1.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.1.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>transformer.h.1.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.1.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>transformer.h.1.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.1.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>transformer.h.1.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.1.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>transformer.h.1.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.1.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>transformer.h.1.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.1.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>transformer.h.1.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.1.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>transformer.h.1.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.1.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>transformer.h.1.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.1.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>transformer.h.1.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.1.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>transformer.h.2.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.2.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>transformer.h.2.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.2.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>transformer.h.2.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.2.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transformer.h.2.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.2.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>transformer.h.2.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.2.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>transformer.h.2.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.2.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>transformer.h.2.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.2.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>transformer.h.2.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.2.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>transformer.h.2.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.2.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>transformer.h.2.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.2.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>transformer.h.2.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.2.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>transformer.h.2.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.2.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>transformer.h.3.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.3.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>transformer.h.3.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.3.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>transformer.h.3.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.3.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>transformer.h.3.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.3.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>transformer.h.3.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.3.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>transformer.h.3.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.3.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>transformer.h.3.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.3.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>transformer.h.3.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.3.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>transformer.h.3.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.3.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>transformer.h.3.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.3.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>transformer.h.3.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.3.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>transformer.h.3.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.3.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>transformer.h.4.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.4.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>transformer.h.4.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.4.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>transformer.h.4.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.4.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>transformer.h.4.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.4.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>transformer.h.4.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.4.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>transformer.h.4.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.4.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>transformer.h.4.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.4.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>transformer.h.4.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.4.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>transformer.h.4.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.4.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>transformer.h.4.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.4.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>transformer.h.4.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.4.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>transformer.h.4.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.4.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>transformer.h.5.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.5.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>transformer.h.5.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.5.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>transformer.h.5.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.5.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>transformer.h.5.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.5.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>transformer.h.5.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.5.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>transformer.h.5.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.5.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>transformer.h.5.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.5.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>transformer.h.5.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.5.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>transformer.h.5.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.5.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>transformer.h.5.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.5.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>transformer.h.5.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.5.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>transformer.h.5.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.5.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>transformer.h.6.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.6.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>transformer.h.6.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.6.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>transformer.h.6.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.6.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>transformer.h.6.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.6.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>transformer.h.6.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.6.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>transformer.h.6.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.6.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>transformer.h.6.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.6.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>transformer.h.6.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.6.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>transformer.h.6.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.6.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>transformer.h.6.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.6.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>transformer.h.6.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.6.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>transformer.h.6.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.6.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>transformer.h.7.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.7.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>transformer.h.7.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.7.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>transformer.h.7.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.7.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>transformer.h.7.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.7.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>transformer.h.7.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.7.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>transformer.h.7.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.7.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>transformer.h.7.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.7.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>transformer.h.7.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.7.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>transformer.h.7.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.7.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>transformer.h.7.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.7.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>transformer.h.7.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.7.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>transformer.h.7.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.7.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>transformer.h.8.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.8.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>transformer.h.8.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.8.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>transformer.h.8.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.8.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>transformer.h.8.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.8.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>transformer.h.8.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.8.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>transformer.h.8.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.8.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>transformer.h.8.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.8.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>transformer.h.8.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.8.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>transformer.h.8.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.8.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>transformer.h.8.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.8.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>transformer.h.8.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.8.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>transformer.h.8.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.8.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>transformer.h.9.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.9.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>transformer.h.9.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.9.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>transformer.h.9.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.9.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>transformer.h.9.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.9.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>transformer.h.9.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.9.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>transformer.h.9.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.9.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>transformer.h.9.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.9.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>transformer.h.9.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.9.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>transformer.h.9.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.9.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>transformer.h.9.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.9.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>transformer.h.9.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.9.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>transformer.h.9.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.9.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>transformer.h.10.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.10.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>transformer.h.10.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.10.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>transformer.h.10.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.10.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>transformer.h.10.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.10.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>transformer.h.10.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.10.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>transformer.h.10.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.10.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>transformer.h.10.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.10.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>transformer.h.10.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.10.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>transformer.h.10.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.10.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>transformer.h.10.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.10.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>transformer.h.10.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.10.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>transformer.h.10.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.10.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>transformer.h.11.ln_1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.11.ln1.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>transformer.h.11.ln_1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.11.ln1.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>transformer.h.11.attn.c_attn.weight</td>\n",
       "      <td>(768, 2304)</td>\n",
       "      <td>decoder_blocks.11.attn.W_QKV.weight</td>\n",
       "      <td>(2304, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>transformer.h.11.attn.c_attn.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "      <td>decoder_blocks.11.attn.W_QKV.bias</td>\n",
       "      <td>(2304,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>transformer.h.11.attn.c_proj.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "      <td>decoder_blocks.11.attn.W_O.weight</td>\n",
       "      <td>(768, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>transformer.h.11.attn.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.11.attn.W_O.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>transformer.h.11.ln_2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.11.ln2.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>transformer.h.11.ln_2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.11.ln2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>transformer.h.11.mlp.c_fc.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "      <td>decoder_blocks.11.mlp.mlp_block.0.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>transformer.h.11.mlp.c_fc.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "      <td>decoder_blocks.11.mlp.mlp_block.0.bias</td>\n",
       "      <td>(3072,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>transformer.h.11.mlp.c_proj.weight</td>\n",
       "      <td>(3072, 768)</td>\n",
       "      <td>decoder_blocks.11.mlp.mlp_block.2.weight</td>\n",
       "      <td>(768, 3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>transformer.h.11.mlp.c_proj.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>decoder_blocks.11.mlp.mlp_block.2.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>transformer.ln_f.weight</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>final_layer_norm.weight</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>transformer.ln_f.bias</td>\n",
       "      <td>(768,)</td>\n",
       "      <td>final_layer_norm.bias</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              their name   their shape  \\\n",
       "0                 transformer.wte.weight  (50257, 768)   \n",
       "1                 transformer.wpe.weight   (1024, 768)   \n",
       "2            transformer.h.0.ln_1.weight        (768,)   \n",
       "3              transformer.h.0.ln_1.bias        (768,)   \n",
       "4     transformer.h.0.attn.c_attn.weight   (768, 2304)   \n",
       "5       transformer.h.0.attn.c_attn.bias       (2304,)   \n",
       "6     transformer.h.0.attn.c_proj.weight    (768, 768)   \n",
       "7       transformer.h.0.attn.c_proj.bias        (768,)   \n",
       "8            transformer.h.0.ln_2.weight        (768,)   \n",
       "9              transformer.h.0.ln_2.bias        (768,)   \n",
       "10       transformer.h.0.mlp.c_fc.weight   (768, 3072)   \n",
       "11         transformer.h.0.mlp.c_fc.bias       (3072,)   \n",
       "12     transformer.h.0.mlp.c_proj.weight   (3072, 768)   \n",
       "13       transformer.h.0.mlp.c_proj.bias        (768,)   \n",
       "14           transformer.h.1.ln_1.weight        (768,)   \n",
       "15             transformer.h.1.ln_1.bias        (768,)   \n",
       "16    transformer.h.1.attn.c_attn.weight   (768, 2304)   \n",
       "17      transformer.h.1.attn.c_attn.bias       (2304,)   \n",
       "18    transformer.h.1.attn.c_proj.weight    (768, 768)   \n",
       "19      transformer.h.1.attn.c_proj.bias        (768,)   \n",
       "20           transformer.h.1.ln_2.weight        (768,)   \n",
       "21             transformer.h.1.ln_2.bias        (768,)   \n",
       "22       transformer.h.1.mlp.c_fc.weight   (768, 3072)   \n",
       "23         transformer.h.1.mlp.c_fc.bias       (3072,)   \n",
       "24     transformer.h.1.mlp.c_proj.weight   (3072, 768)   \n",
       "25       transformer.h.1.mlp.c_proj.bias        (768,)   \n",
       "26           transformer.h.2.ln_1.weight        (768,)   \n",
       "27             transformer.h.2.ln_1.bias        (768,)   \n",
       "28    transformer.h.2.attn.c_attn.weight   (768, 2304)   \n",
       "29      transformer.h.2.attn.c_attn.bias       (2304,)   \n",
       "30    transformer.h.2.attn.c_proj.weight    (768, 768)   \n",
       "31      transformer.h.2.attn.c_proj.bias        (768,)   \n",
       "32           transformer.h.2.ln_2.weight        (768,)   \n",
       "33             transformer.h.2.ln_2.bias        (768,)   \n",
       "34       transformer.h.2.mlp.c_fc.weight   (768, 3072)   \n",
       "35         transformer.h.2.mlp.c_fc.bias       (3072,)   \n",
       "36     transformer.h.2.mlp.c_proj.weight   (3072, 768)   \n",
       "37       transformer.h.2.mlp.c_proj.bias        (768,)   \n",
       "38           transformer.h.3.ln_1.weight        (768,)   \n",
       "39             transformer.h.3.ln_1.bias        (768,)   \n",
       "40    transformer.h.3.attn.c_attn.weight   (768, 2304)   \n",
       "41      transformer.h.3.attn.c_attn.bias       (2304,)   \n",
       "42    transformer.h.3.attn.c_proj.weight    (768, 768)   \n",
       "43      transformer.h.3.attn.c_proj.bias        (768,)   \n",
       "44           transformer.h.3.ln_2.weight        (768,)   \n",
       "45             transformer.h.3.ln_2.bias        (768,)   \n",
       "46       transformer.h.3.mlp.c_fc.weight   (768, 3072)   \n",
       "47         transformer.h.3.mlp.c_fc.bias       (3072,)   \n",
       "48     transformer.h.3.mlp.c_proj.weight   (3072, 768)   \n",
       "49       transformer.h.3.mlp.c_proj.bias        (768,)   \n",
       "50           transformer.h.4.ln_1.weight        (768,)   \n",
       "51             transformer.h.4.ln_1.bias        (768,)   \n",
       "52    transformer.h.4.attn.c_attn.weight   (768, 2304)   \n",
       "53      transformer.h.4.attn.c_attn.bias       (2304,)   \n",
       "54    transformer.h.4.attn.c_proj.weight    (768, 768)   \n",
       "55      transformer.h.4.attn.c_proj.bias        (768,)   \n",
       "56           transformer.h.4.ln_2.weight        (768,)   \n",
       "57             transformer.h.4.ln_2.bias        (768,)   \n",
       "58       transformer.h.4.mlp.c_fc.weight   (768, 3072)   \n",
       "59         transformer.h.4.mlp.c_fc.bias       (3072,)   \n",
       "60     transformer.h.4.mlp.c_proj.weight   (3072, 768)   \n",
       "61       transformer.h.4.mlp.c_proj.bias        (768,)   \n",
       "62           transformer.h.5.ln_1.weight        (768,)   \n",
       "63             transformer.h.5.ln_1.bias        (768,)   \n",
       "64    transformer.h.5.attn.c_attn.weight   (768, 2304)   \n",
       "65      transformer.h.5.attn.c_attn.bias       (2304,)   \n",
       "66    transformer.h.5.attn.c_proj.weight    (768, 768)   \n",
       "67      transformer.h.5.attn.c_proj.bias        (768,)   \n",
       "68           transformer.h.5.ln_2.weight        (768,)   \n",
       "69             transformer.h.5.ln_2.bias        (768,)   \n",
       "70       transformer.h.5.mlp.c_fc.weight   (768, 3072)   \n",
       "71         transformer.h.5.mlp.c_fc.bias       (3072,)   \n",
       "72     transformer.h.5.mlp.c_proj.weight   (3072, 768)   \n",
       "73       transformer.h.5.mlp.c_proj.bias        (768,)   \n",
       "74           transformer.h.6.ln_1.weight        (768,)   \n",
       "75             transformer.h.6.ln_1.bias        (768,)   \n",
       "76    transformer.h.6.attn.c_attn.weight   (768, 2304)   \n",
       "77      transformer.h.6.attn.c_attn.bias       (2304,)   \n",
       "78    transformer.h.6.attn.c_proj.weight    (768, 768)   \n",
       "79      transformer.h.6.attn.c_proj.bias        (768,)   \n",
       "80           transformer.h.6.ln_2.weight        (768,)   \n",
       "81             transformer.h.6.ln_2.bias        (768,)   \n",
       "82       transformer.h.6.mlp.c_fc.weight   (768, 3072)   \n",
       "83         transformer.h.6.mlp.c_fc.bias       (3072,)   \n",
       "84     transformer.h.6.mlp.c_proj.weight   (3072, 768)   \n",
       "85       transformer.h.6.mlp.c_proj.bias        (768,)   \n",
       "86           transformer.h.7.ln_1.weight        (768,)   \n",
       "87             transformer.h.7.ln_1.bias        (768,)   \n",
       "88    transformer.h.7.attn.c_attn.weight   (768, 2304)   \n",
       "89      transformer.h.7.attn.c_attn.bias       (2304,)   \n",
       "90    transformer.h.7.attn.c_proj.weight    (768, 768)   \n",
       "91      transformer.h.7.attn.c_proj.bias        (768,)   \n",
       "92           transformer.h.7.ln_2.weight        (768,)   \n",
       "93             transformer.h.7.ln_2.bias        (768,)   \n",
       "94       transformer.h.7.mlp.c_fc.weight   (768, 3072)   \n",
       "95         transformer.h.7.mlp.c_fc.bias       (3072,)   \n",
       "96     transformer.h.7.mlp.c_proj.weight   (3072, 768)   \n",
       "97       transformer.h.7.mlp.c_proj.bias        (768,)   \n",
       "98           transformer.h.8.ln_1.weight        (768,)   \n",
       "99             transformer.h.8.ln_1.bias        (768,)   \n",
       "100   transformer.h.8.attn.c_attn.weight   (768, 2304)   \n",
       "101     transformer.h.8.attn.c_attn.bias       (2304,)   \n",
       "102   transformer.h.8.attn.c_proj.weight    (768, 768)   \n",
       "103     transformer.h.8.attn.c_proj.bias        (768,)   \n",
       "104          transformer.h.8.ln_2.weight        (768,)   \n",
       "105            transformer.h.8.ln_2.bias        (768,)   \n",
       "106      transformer.h.8.mlp.c_fc.weight   (768, 3072)   \n",
       "107        transformer.h.8.mlp.c_fc.bias       (3072,)   \n",
       "108    transformer.h.8.mlp.c_proj.weight   (3072, 768)   \n",
       "109      transformer.h.8.mlp.c_proj.bias        (768,)   \n",
       "110          transformer.h.9.ln_1.weight        (768,)   \n",
       "111            transformer.h.9.ln_1.bias        (768,)   \n",
       "112   transformer.h.9.attn.c_attn.weight   (768, 2304)   \n",
       "113     transformer.h.9.attn.c_attn.bias       (2304,)   \n",
       "114   transformer.h.9.attn.c_proj.weight    (768, 768)   \n",
       "115     transformer.h.9.attn.c_proj.bias        (768,)   \n",
       "116          transformer.h.9.ln_2.weight        (768,)   \n",
       "117            transformer.h.9.ln_2.bias        (768,)   \n",
       "118      transformer.h.9.mlp.c_fc.weight   (768, 3072)   \n",
       "119        transformer.h.9.mlp.c_fc.bias       (3072,)   \n",
       "120    transformer.h.9.mlp.c_proj.weight   (3072, 768)   \n",
       "121      transformer.h.9.mlp.c_proj.bias        (768,)   \n",
       "122         transformer.h.10.ln_1.weight        (768,)   \n",
       "123           transformer.h.10.ln_1.bias        (768,)   \n",
       "124  transformer.h.10.attn.c_attn.weight   (768, 2304)   \n",
       "125    transformer.h.10.attn.c_attn.bias       (2304,)   \n",
       "126  transformer.h.10.attn.c_proj.weight    (768, 768)   \n",
       "127    transformer.h.10.attn.c_proj.bias        (768,)   \n",
       "128         transformer.h.10.ln_2.weight        (768,)   \n",
       "129           transformer.h.10.ln_2.bias        (768,)   \n",
       "130     transformer.h.10.mlp.c_fc.weight   (768, 3072)   \n",
       "131       transformer.h.10.mlp.c_fc.bias       (3072,)   \n",
       "132   transformer.h.10.mlp.c_proj.weight   (3072, 768)   \n",
       "133     transformer.h.10.mlp.c_proj.bias        (768,)   \n",
       "134         transformer.h.11.ln_1.weight        (768,)   \n",
       "135           transformer.h.11.ln_1.bias        (768,)   \n",
       "136  transformer.h.11.attn.c_attn.weight   (768, 2304)   \n",
       "137    transformer.h.11.attn.c_attn.bias       (2304,)   \n",
       "138  transformer.h.11.attn.c_proj.weight    (768, 768)   \n",
       "139    transformer.h.11.attn.c_proj.bias        (768,)   \n",
       "140         transformer.h.11.ln_2.weight        (768,)   \n",
       "141           transformer.h.11.ln_2.bias        (768,)   \n",
       "142     transformer.h.11.mlp.c_fc.weight   (768, 3072)   \n",
       "143       transformer.h.11.mlp.c_fc.bias       (3072,)   \n",
       "144   transformer.h.11.mlp.c_proj.weight   (3072, 768)   \n",
       "145     transformer.h.11.mlp.c_proj.bias        (768,)   \n",
       "146              transformer.ln_f.weight        (768,)   \n",
       "147                transformer.ln_f.bias        (768,)   \n",
       "\n",
       "                                    your name    your shape  \n",
       "0                       text_embedding.weight  (50257, 768)  \n",
       "1                   position_embedding.weight   (1024, 768)  \n",
       "2                 decoder_blocks.0.ln1.weight        (768,)  \n",
       "3                   decoder_blocks.0.ln1.bias        (768,)  \n",
       "4          decoder_blocks.0.attn.W_QKV.weight   (2304, 768)  \n",
       "5            decoder_blocks.0.attn.W_QKV.bias       (2304,)  \n",
       "6            decoder_blocks.0.attn.W_O.weight    (768, 768)  \n",
       "7              decoder_blocks.0.attn.W_O.bias        (768,)  \n",
       "8                 decoder_blocks.0.ln2.weight        (768,)  \n",
       "9                   decoder_blocks.0.ln2.bias        (768,)  \n",
       "10    decoder_blocks.0.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "11      decoder_blocks.0.mlp.mlp_block.0.bias       (3072,)  \n",
       "12    decoder_blocks.0.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "13      decoder_blocks.0.mlp.mlp_block.2.bias        (768,)  \n",
       "14                decoder_blocks.1.ln1.weight        (768,)  \n",
       "15                  decoder_blocks.1.ln1.bias        (768,)  \n",
       "16         decoder_blocks.1.attn.W_QKV.weight   (2304, 768)  \n",
       "17           decoder_blocks.1.attn.W_QKV.bias       (2304,)  \n",
       "18           decoder_blocks.1.attn.W_O.weight    (768, 768)  \n",
       "19             decoder_blocks.1.attn.W_O.bias        (768,)  \n",
       "20                decoder_blocks.1.ln2.weight        (768,)  \n",
       "21                  decoder_blocks.1.ln2.bias        (768,)  \n",
       "22    decoder_blocks.1.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "23      decoder_blocks.1.mlp.mlp_block.0.bias       (3072,)  \n",
       "24    decoder_blocks.1.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "25      decoder_blocks.1.mlp.mlp_block.2.bias        (768,)  \n",
       "26                decoder_blocks.2.ln1.weight        (768,)  \n",
       "27                  decoder_blocks.2.ln1.bias        (768,)  \n",
       "28         decoder_blocks.2.attn.W_QKV.weight   (2304, 768)  \n",
       "29           decoder_blocks.2.attn.W_QKV.bias       (2304,)  \n",
       "30           decoder_blocks.2.attn.W_O.weight    (768, 768)  \n",
       "31             decoder_blocks.2.attn.W_O.bias        (768,)  \n",
       "32                decoder_blocks.2.ln2.weight        (768,)  \n",
       "33                  decoder_blocks.2.ln2.bias        (768,)  \n",
       "34    decoder_blocks.2.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "35      decoder_blocks.2.mlp.mlp_block.0.bias       (3072,)  \n",
       "36    decoder_blocks.2.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "37      decoder_blocks.2.mlp.mlp_block.2.bias        (768,)  \n",
       "38                decoder_blocks.3.ln1.weight        (768,)  \n",
       "39                  decoder_blocks.3.ln1.bias        (768,)  \n",
       "40         decoder_blocks.3.attn.W_QKV.weight   (2304, 768)  \n",
       "41           decoder_blocks.3.attn.W_QKV.bias       (2304,)  \n",
       "42           decoder_blocks.3.attn.W_O.weight    (768, 768)  \n",
       "43             decoder_blocks.3.attn.W_O.bias        (768,)  \n",
       "44                decoder_blocks.3.ln2.weight        (768,)  \n",
       "45                  decoder_blocks.3.ln2.bias        (768,)  \n",
       "46    decoder_blocks.3.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "47      decoder_blocks.3.mlp.mlp_block.0.bias       (3072,)  \n",
       "48    decoder_blocks.3.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "49      decoder_blocks.3.mlp.mlp_block.2.bias        (768,)  \n",
       "50                decoder_blocks.4.ln1.weight        (768,)  \n",
       "51                  decoder_blocks.4.ln1.bias        (768,)  \n",
       "52         decoder_blocks.4.attn.W_QKV.weight   (2304, 768)  \n",
       "53           decoder_blocks.4.attn.W_QKV.bias       (2304,)  \n",
       "54           decoder_blocks.4.attn.W_O.weight    (768, 768)  \n",
       "55             decoder_blocks.4.attn.W_O.bias        (768,)  \n",
       "56                decoder_blocks.4.ln2.weight        (768,)  \n",
       "57                  decoder_blocks.4.ln2.bias        (768,)  \n",
       "58    decoder_blocks.4.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "59      decoder_blocks.4.mlp.mlp_block.0.bias       (3072,)  \n",
       "60    decoder_blocks.4.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "61      decoder_blocks.4.mlp.mlp_block.2.bias        (768,)  \n",
       "62                decoder_blocks.5.ln1.weight        (768,)  \n",
       "63                  decoder_blocks.5.ln1.bias        (768,)  \n",
       "64         decoder_blocks.5.attn.W_QKV.weight   (2304, 768)  \n",
       "65           decoder_blocks.5.attn.W_QKV.bias       (2304,)  \n",
       "66           decoder_blocks.5.attn.W_O.weight    (768, 768)  \n",
       "67             decoder_blocks.5.attn.W_O.bias        (768,)  \n",
       "68                decoder_blocks.5.ln2.weight        (768,)  \n",
       "69                  decoder_blocks.5.ln2.bias        (768,)  \n",
       "70    decoder_blocks.5.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "71      decoder_blocks.5.mlp.mlp_block.0.bias       (3072,)  \n",
       "72    decoder_blocks.5.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "73      decoder_blocks.5.mlp.mlp_block.2.bias        (768,)  \n",
       "74                decoder_blocks.6.ln1.weight        (768,)  \n",
       "75                  decoder_blocks.6.ln1.bias        (768,)  \n",
       "76         decoder_blocks.6.attn.W_QKV.weight   (2304, 768)  \n",
       "77           decoder_blocks.6.attn.W_QKV.bias       (2304,)  \n",
       "78           decoder_blocks.6.attn.W_O.weight    (768, 768)  \n",
       "79             decoder_blocks.6.attn.W_O.bias        (768,)  \n",
       "80                decoder_blocks.6.ln2.weight        (768,)  \n",
       "81                  decoder_blocks.6.ln2.bias        (768,)  \n",
       "82    decoder_blocks.6.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "83      decoder_blocks.6.mlp.mlp_block.0.bias       (3072,)  \n",
       "84    decoder_blocks.6.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "85      decoder_blocks.6.mlp.mlp_block.2.bias        (768,)  \n",
       "86                decoder_blocks.7.ln1.weight        (768,)  \n",
       "87                  decoder_blocks.7.ln1.bias        (768,)  \n",
       "88         decoder_blocks.7.attn.W_QKV.weight   (2304, 768)  \n",
       "89           decoder_blocks.7.attn.W_QKV.bias       (2304,)  \n",
       "90           decoder_blocks.7.attn.W_O.weight    (768, 768)  \n",
       "91             decoder_blocks.7.attn.W_O.bias        (768,)  \n",
       "92                decoder_blocks.7.ln2.weight        (768,)  \n",
       "93                  decoder_blocks.7.ln2.bias        (768,)  \n",
       "94    decoder_blocks.7.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "95      decoder_blocks.7.mlp.mlp_block.0.bias       (3072,)  \n",
       "96    decoder_blocks.7.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "97      decoder_blocks.7.mlp.mlp_block.2.bias        (768,)  \n",
       "98                decoder_blocks.8.ln1.weight        (768,)  \n",
       "99                  decoder_blocks.8.ln1.bias        (768,)  \n",
       "100        decoder_blocks.8.attn.W_QKV.weight   (2304, 768)  \n",
       "101          decoder_blocks.8.attn.W_QKV.bias       (2304,)  \n",
       "102          decoder_blocks.8.attn.W_O.weight    (768, 768)  \n",
       "103            decoder_blocks.8.attn.W_O.bias        (768,)  \n",
       "104               decoder_blocks.8.ln2.weight        (768,)  \n",
       "105                 decoder_blocks.8.ln2.bias        (768,)  \n",
       "106   decoder_blocks.8.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "107     decoder_blocks.8.mlp.mlp_block.0.bias       (3072,)  \n",
       "108   decoder_blocks.8.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "109     decoder_blocks.8.mlp.mlp_block.2.bias        (768,)  \n",
       "110               decoder_blocks.9.ln1.weight        (768,)  \n",
       "111                 decoder_blocks.9.ln1.bias        (768,)  \n",
       "112        decoder_blocks.9.attn.W_QKV.weight   (2304, 768)  \n",
       "113          decoder_blocks.9.attn.W_QKV.bias       (2304,)  \n",
       "114          decoder_blocks.9.attn.W_O.weight    (768, 768)  \n",
       "115            decoder_blocks.9.attn.W_O.bias        (768,)  \n",
       "116               decoder_blocks.9.ln2.weight        (768,)  \n",
       "117                 decoder_blocks.9.ln2.bias        (768,)  \n",
       "118   decoder_blocks.9.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "119     decoder_blocks.9.mlp.mlp_block.0.bias       (3072,)  \n",
       "120   decoder_blocks.9.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "121     decoder_blocks.9.mlp.mlp_block.2.bias        (768,)  \n",
       "122              decoder_blocks.10.ln1.weight        (768,)  \n",
       "123                decoder_blocks.10.ln1.bias        (768,)  \n",
       "124       decoder_blocks.10.attn.W_QKV.weight   (2304, 768)  \n",
       "125         decoder_blocks.10.attn.W_QKV.bias       (2304,)  \n",
       "126         decoder_blocks.10.attn.W_O.weight    (768, 768)  \n",
       "127           decoder_blocks.10.attn.W_O.bias        (768,)  \n",
       "128              decoder_blocks.10.ln2.weight        (768,)  \n",
       "129                decoder_blocks.10.ln2.bias        (768,)  \n",
       "130  decoder_blocks.10.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "131    decoder_blocks.10.mlp.mlp_block.0.bias       (3072,)  \n",
       "132  decoder_blocks.10.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "133    decoder_blocks.10.mlp.mlp_block.2.bias        (768,)  \n",
       "134              decoder_blocks.11.ln1.weight        (768,)  \n",
       "135                decoder_blocks.11.ln1.bias        (768,)  \n",
       "136       decoder_blocks.11.attn.W_QKV.weight   (2304, 768)  \n",
       "137         decoder_blocks.11.attn.W_QKV.bias       (2304,)  \n",
       "138         decoder_blocks.11.attn.W_O.weight    (768, 768)  \n",
       "139           decoder_blocks.11.attn.W_O.bias        (768,)  \n",
       "140              decoder_blocks.11.ln2.weight        (768,)  \n",
       "141                decoder_blocks.11.ln2.bias        (768,)  \n",
       "142  decoder_blocks.11.mlp.mlp_block.0.weight   (3072, 768)  \n",
       "143    decoder_blocks.11.mlp.mlp_block.0.bias       (3072,)  \n",
       "144  decoder_blocks.11.mlp.mlp_block.2.weight   (768, 3072)  \n",
       "145    decoder_blocks.11.mlp.mlp_block.2.bias        (768,)  \n",
       "146                   final_layer_norm.weight        (768,)  \n",
       "147                     final_layer_norm.bias        (768,)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from itertools import zip_longest\n",
    "def compare_models(my_model, realmodel):\n",
    "    \n",
    "    pretraineddict = dict(realmodel.named_parameters())\n",
    "    my_state = dict(my_model.named_parameters())\n",
    "\n",
    "\n",
    "    keys_to_iterate = []\n",
    "\n",
    "    for pretrainedkey, pretrainedvalue in pretraineddict.items():\n",
    "        remove_these= [] #[\"attn.masked_bias\", \".attn.bias\", \"lm_head.weight\"]\n",
    "        for suffix in remove_these:\n",
    "            if pretrainedkey.endswith(suffix):\n",
    "                break\n",
    "        else:\n",
    "            keys_to_iterate.append(pretrainedkey)\n",
    "\n",
    "    # match keys\n",
    "    remaining_keys = list(my_state.keys())\n",
    "    matched_keys = []\n",
    "    for key in keys_to_iterate:\n",
    "        for mykey in remaining_keys:\n",
    "            if key.endswith(\"weight\") and not (key.endswith(\"wte.weight\") or key.endswith(\"wpe.weight\")):\n",
    "                # rotate shape\n",
    "                shape = pretraineddict[key].T.shape\n",
    "            else:\n",
    "                shape = pretraineddict[key].shape\n",
    "\n",
    "            myshape = my_state[mykey].shape\n",
    "            if shape == myshape:\n",
    "                matched_keys.append(mykey)\n",
    "                remaining_keys.remove(mykey)\n",
    "                break\n",
    "        else: \n",
    "            print(f\"No match found for key {key}\")\n",
    "            \n",
    "    print(f\"remaining keys = {remaining_keys}\")\n",
    "\n",
    "    print(f\"len(pretraineddict)={len(keys_to_iterate)}\\tlen(my_state)={len(my_state)}\")\n",
    "    utils.print_param_count(my_model, realmodel)\n",
    "    \n",
    "    df = pd.DataFrame.from_records(\n",
    "        [(tk, tuple(pretraineddict[tk].shape), mk, tuple(my_state[mk].shape)) for (tk, mk) in zip(keys_to_iterate, matched_keys)],\n",
    "        columns=[\"their name\", \"their shape\", \"your name\", \"your shape\"],\n",
    "    )\n",
    "    # if len(pretraineddict)!= len(my_state):\n",
    "        # for tk, tv in pretraineddict.items():\n",
    "        #     print(f\"{tk}\\t{tuple(tv.shape)}\")\n",
    "    \n",
    "        # for tk, tv in my_state.items():\n",
    "        #     print(f\"{tk}\\t{tuple(tv.shape)}\")\n",
    "\n",
    "    with pd.option_context(\"display.max_rows\", None):  # type: ignore\n",
    "        display(df)\n",
    "\n",
    "compare_models(model,gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied params: transformer.wte.weight -> text_embedding.weight\n",
      "Copied params: transformer.wpe.weight -> position_embedding.weight\n",
      "Copied params.T: transformer.h.0.ln_1.weight -> decoder_blocks.0.ln1.weight\n",
      "Copied params: transformer.h.0.ln_1.bias -> decoder_blocks.0.ln1.bias\n",
      "Copied params.T: transformer.h.0.attn.c_attn.weight -> decoder_blocks.0.attn.W_QKV.weight\n",
      "Copied params: transformer.h.0.attn.c_attn.bias -> decoder_blocks.0.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.0.attn.c_proj.weight -> decoder_blocks.0.attn.W_O.weight\n",
      "Copied params: transformer.h.0.attn.c_proj.bias -> decoder_blocks.0.attn.W_O.bias\n",
      "Copied params.T: transformer.h.0.ln_2.weight -> decoder_blocks.0.ln2.weight\n",
      "Copied params: transformer.h.0.ln_2.bias -> decoder_blocks.0.ln2.bias\n",
      "Copied params.T: transformer.h.0.mlp.c_fc.weight -> decoder_blocks.0.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.0.mlp.c_fc.bias -> decoder_blocks.0.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.0.mlp.c_proj.weight -> decoder_blocks.0.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.0.mlp.c_proj.bias -> decoder_blocks.0.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.1.ln_1.weight -> decoder_blocks.1.ln1.weight\n",
      "Copied params: transformer.h.1.ln_1.bias -> decoder_blocks.1.ln1.bias\n",
      "Copied params.T: transformer.h.1.attn.c_attn.weight -> decoder_blocks.1.attn.W_QKV.weight\n",
      "Copied params: transformer.h.1.attn.c_attn.bias -> decoder_blocks.1.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.1.attn.c_proj.weight -> decoder_blocks.1.attn.W_O.weight\n",
      "Copied params: transformer.h.1.attn.c_proj.bias -> decoder_blocks.1.attn.W_O.bias\n",
      "Copied params.T: transformer.h.1.ln_2.weight -> decoder_blocks.1.ln2.weight\n",
      "Copied params: transformer.h.1.ln_2.bias -> decoder_blocks.1.ln2.bias\n",
      "Copied params.T: transformer.h.1.mlp.c_fc.weight -> decoder_blocks.1.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.1.mlp.c_fc.bias -> decoder_blocks.1.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.1.mlp.c_proj.weight -> decoder_blocks.1.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.1.mlp.c_proj.bias -> decoder_blocks.1.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.2.ln_1.weight -> decoder_blocks.2.ln1.weight\n",
      "Copied params: transformer.h.2.ln_1.bias -> decoder_blocks.2.ln1.bias\n",
      "Copied params.T: transformer.h.2.attn.c_attn.weight -> decoder_blocks.2.attn.W_QKV.weight\n",
      "Copied params: transformer.h.2.attn.c_attn.bias -> decoder_blocks.2.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.2.attn.c_proj.weight -> decoder_blocks.2.attn.W_O.weight\n",
      "Copied params: transformer.h.2.attn.c_proj.bias -> decoder_blocks.2.attn.W_O.bias\n",
      "Copied params.T: transformer.h.2.ln_2.weight -> decoder_blocks.2.ln2.weight\n",
      "Copied params: transformer.h.2.ln_2.bias -> decoder_blocks.2.ln2.bias\n",
      "Copied params.T: transformer.h.2.mlp.c_fc.weight -> decoder_blocks.2.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.2.mlp.c_fc.bias -> decoder_blocks.2.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.2.mlp.c_proj.weight -> decoder_blocks.2.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.2.mlp.c_proj.bias -> decoder_blocks.2.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.3.ln_1.weight -> decoder_blocks.3.ln1.weight\n",
      "Copied params: transformer.h.3.ln_1.bias -> decoder_blocks.3.ln1.bias\n",
      "Copied params.T: transformer.h.3.attn.c_attn.weight -> decoder_blocks.3.attn.W_QKV.weight\n",
      "Copied params: transformer.h.3.attn.c_attn.bias -> decoder_blocks.3.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.3.attn.c_proj.weight -> decoder_blocks.3.attn.W_O.weight\n",
      "Copied params: transformer.h.3.attn.c_proj.bias -> decoder_blocks.3.attn.W_O.bias\n",
      "Copied params.T: transformer.h.3.ln_2.weight -> decoder_blocks.3.ln2.weight\n",
      "Copied params: transformer.h.3.ln_2.bias -> decoder_blocks.3.ln2.bias\n",
      "Copied params.T: transformer.h.3.mlp.c_fc.weight -> decoder_blocks.3.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.3.mlp.c_fc.bias -> decoder_blocks.3.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.3.mlp.c_proj.weight -> decoder_blocks.3.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.3.mlp.c_proj.bias -> decoder_blocks.3.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.4.ln_1.weight -> decoder_blocks.4.ln1.weight\n",
      "Copied params: transformer.h.4.ln_1.bias -> decoder_blocks.4.ln1.bias\n",
      "Copied params.T: transformer.h.4.attn.c_attn.weight -> decoder_blocks.4.attn.W_QKV.weight\n",
      "Copied params: transformer.h.4.attn.c_attn.bias -> decoder_blocks.4.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.4.attn.c_proj.weight -> decoder_blocks.4.attn.W_O.weight\n",
      "Copied params: transformer.h.4.attn.c_proj.bias -> decoder_blocks.4.attn.W_O.bias\n",
      "Copied params.T: transformer.h.4.ln_2.weight -> decoder_blocks.4.ln2.weight\n",
      "Copied params: transformer.h.4.ln_2.bias -> decoder_blocks.4.ln2.bias\n",
      "Copied params.T: transformer.h.4.mlp.c_fc.weight -> decoder_blocks.4.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.4.mlp.c_fc.bias -> decoder_blocks.4.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.4.mlp.c_proj.weight -> decoder_blocks.4.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.4.mlp.c_proj.bias -> decoder_blocks.4.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.5.ln_1.weight -> decoder_blocks.5.ln1.weight\n",
      "Copied params: transformer.h.5.ln_1.bias -> decoder_blocks.5.ln1.bias\n",
      "Copied params.T: transformer.h.5.attn.c_attn.weight -> decoder_blocks.5.attn.W_QKV.weight\n",
      "Copied params: transformer.h.5.attn.c_attn.bias -> decoder_blocks.5.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.5.attn.c_proj.weight -> decoder_blocks.5.attn.W_O.weight\n",
      "Copied params: transformer.h.5.attn.c_proj.bias -> decoder_blocks.5.attn.W_O.bias\n",
      "Copied params.T: transformer.h.5.ln_2.weight -> decoder_blocks.5.ln2.weight\n",
      "Copied params: transformer.h.5.ln_2.bias -> decoder_blocks.5.ln2.bias\n",
      "Copied params.T: transformer.h.5.mlp.c_fc.weight -> decoder_blocks.5.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.5.mlp.c_fc.bias -> decoder_blocks.5.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.5.mlp.c_proj.weight -> decoder_blocks.5.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.5.mlp.c_proj.bias -> decoder_blocks.5.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.6.ln_1.weight -> decoder_blocks.6.ln1.weight\n",
      "Copied params: transformer.h.6.ln_1.bias -> decoder_blocks.6.ln1.bias\n",
      "Copied params.T: transformer.h.6.attn.c_attn.weight -> decoder_blocks.6.attn.W_QKV.weight\n",
      "Copied params: transformer.h.6.attn.c_attn.bias -> decoder_blocks.6.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.6.attn.c_proj.weight -> decoder_blocks.6.attn.W_O.weight\n",
      "Copied params: transformer.h.6.attn.c_proj.bias -> decoder_blocks.6.attn.W_O.bias\n",
      "Copied params.T: transformer.h.6.ln_2.weight -> decoder_blocks.6.ln2.weight\n",
      "Copied params: transformer.h.6.ln_2.bias -> decoder_blocks.6.ln2.bias\n",
      "Copied params.T: transformer.h.6.mlp.c_fc.weight -> decoder_blocks.6.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.6.mlp.c_fc.bias -> decoder_blocks.6.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.6.mlp.c_proj.weight -> decoder_blocks.6.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.6.mlp.c_proj.bias -> decoder_blocks.6.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.7.ln_1.weight -> decoder_blocks.7.ln1.weight\n",
      "Copied params: transformer.h.7.ln_1.bias -> decoder_blocks.7.ln1.bias\n",
      "Copied params.T: transformer.h.7.attn.c_attn.weight -> decoder_blocks.7.attn.W_QKV.weight\n",
      "Copied params: transformer.h.7.attn.c_attn.bias -> decoder_blocks.7.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.7.attn.c_proj.weight -> decoder_blocks.7.attn.W_O.weight\n",
      "Copied params: transformer.h.7.attn.c_proj.bias -> decoder_blocks.7.attn.W_O.bias\n",
      "Copied params.T: transformer.h.7.ln_2.weight -> decoder_blocks.7.ln2.weight\n",
      "Copied params: transformer.h.7.ln_2.bias -> decoder_blocks.7.ln2.bias\n",
      "Copied params.T: transformer.h.7.mlp.c_fc.weight -> decoder_blocks.7.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.7.mlp.c_fc.bias -> decoder_blocks.7.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.7.mlp.c_proj.weight -> decoder_blocks.7.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.7.mlp.c_proj.bias -> decoder_blocks.7.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.8.ln_1.weight -> decoder_blocks.8.ln1.weight\n",
      "Copied params: transformer.h.8.ln_1.bias -> decoder_blocks.8.ln1.bias\n",
      "Copied params.T: transformer.h.8.attn.c_attn.weight -> decoder_blocks.8.attn.W_QKV.weight\n",
      "Copied params: transformer.h.8.attn.c_attn.bias -> decoder_blocks.8.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.8.attn.c_proj.weight -> decoder_blocks.8.attn.W_O.weight\n",
      "Copied params: transformer.h.8.attn.c_proj.bias -> decoder_blocks.8.attn.W_O.bias\n",
      "Copied params.T: transformer.h.8.ln_2.weight -> decoder_blocks.8.ln2.weight\n",
      "Copied params: transformer.h.8.ln_2.bias -> decoder_blocks.8.ln2.bias\n",
      "Copied params.T: transformer.h.8.mlp.c_fc.weight -> decoder_blocks.8.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.8.mlp.c_fc.bias -> decoder_blocks.8.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.8.mlp.c_proj.weight -> decoder_blocks.8.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.8.mlp.c_proj.bias -> decoder_blocks.8.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.9.ln_1.weight -> decoder_blocks.9.ln1.weight\n",
      "Copied params: transformer.h.9.ln_1.bias -> decoder_blocks.9.ln1.bias\n",
      "Copied params.T: transformer.h.9.attn.c_attn.weight -> decoder_blocks.9.attn.W_QKV.weight\n",
      "Copied params: transformer.h.9.attn.c_attn.bias -> decoder_blocks.9.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.9.attn.c_proj.weight -> decoder_blocks.9.attn.W_O.weight\n",
      "Copied params: transformer.h.9.attn.c_proj.bias -> decoder_blocks.9.attn.W_O.bias\n",
      "Copied params.T: transformer.h.9.ln_2.weight -> decoder_blocks.9.ln2.weight\n",
      "Copied params: transformer.h.9.ln_2.bias -> decoder_blocks.9.ln2.bias\n",
      "Copied params.T: transformer.h.9.mlp.c_fc.weight -> decoder_blocks.9.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.9.mlp.c_fc.bias -> decoder_blocks.9.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.9.mlp.c_proj.weight -> decoder_blocks.9.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.9.mlp.c_proj.bias -> decoder_blocks.9.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.10.ln_1.weight -> decoder_blocks.10.ln1.weight\n",
      "Copied params: transformer.h.10.ln_1.bias -> decoder_blocks.10.ln1.bias\n",
      "Copied params.T: transformer.h.10.attn.c_attn.weight -> decoder_blocks.10.attn.W_QKV.weight\n",
      "Copied params: transformer.h.10.attn.c_attn.bias -> decoder_blocks.10.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.10.attn.c_proj.weight -> decoder_blocks.10.attn.W_O.weight\n",
      "Copied params: transformer.h.10.attn.c_proj.bias -> decoder_blocks.10.attn.W_O.bias\n",
      "Copied params.T: transformer.h.10.ln_2.weight -> decoder_blocks.10.ln2.weight\n",
      "Copied params: transformer.h.10.ln_2.bias -> decoder_blocks.10.ln2.bias\n",
      "Copied params.T: transformer.h.10.mlp.c_fc.weight -> decoder_blocks.10.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.10.mlp.c_fc.bias -> decoder_blocks.10.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.10.mlp.c_proj.weight -> decoder_blocks.10.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.10.mlp.c_proj.bias -> decoder_blocks.10.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.h.11.ln_1.weight -> decoder_blocks.11.ln1.weight\n",
      "Copied params: transformer.h.11.ln_1.bias -> decoder_blocks.11.ln1.bias\n",
      "Copied params.T: transformer.h.11.attn.c_attn.weight -> decoder_blocks.11.attn.W_QKV.weight\n",
      "Copied params: transformer.h.11.attn.c_attn.bias -> decoder_blocks.11.attn.W_QKV.bias\n",
      "Copied params.T: transformer.h.11.attn.c_proj.weight -> decoder_blocks.11.attn.W_O.weight\n",
      "Copied params: transformer.h.11.attn.c_proj.bias -> decoder_blocks.11.attn.W_O.bias\n",
      "Copied params.T: transformer.h.11.ln_2.weight -> decoder_blocks.11.ln2.weight\n",
      "Copied params: transformer.h.11.ln_2.bias -> decoder_blocks.11.ln2.bias\n",
      "Copied params.T: transformer.h.11.mlp.c_fc.weight -> decoder_blocks.11.mlp.mlp_block.0.weight\n",
      "Copied params: transformer.h.11.mlp.c_fc.bias -> decoder_blocks.11.mlp.mlp_block.0.bias\n",
      "Copied params.T: transformer.h.11.mlp.c_proj.weight -> decoder_blocks.11.mlp.mlp_block.2.weight\n",
      "Copied params: transformer.h.11.mlp.c_proj.bias -> decoder_blocks.11.mlp.mlp_block.2.bias\n",
      "Copied params.T: transformer.ln_f.weight -> final_layer_norm.weight\n",
      "Copied params: transformer.ln_f.bias -> final_layer_norm.bias\n"
     ]
    }
   ],
   "source": [
    "def copy_weights_simon(my_model: GPT2Model, pretrained_model: nn.Module) -> GPT2Model:\n",
    "    '''Copy over the weights from gpt to your implementation of gpt.\n",
    "\n",
    "    gpt should be imported using: \n",
    "        gpt = transformers.AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "    Returns your gpt model, with weights loaded in.'''\n",
    "\n",
    "    pretraineddict = dict(pretrained_model.named_parameters())\n",
    "    my_state = dict(my_model.named_parameters())\n",
    "\n",
    "    keys_to_iterate = []\n",
    "\n",
    "    for pretrainedkey, pretrainedvalue in pretraineddict.items():\n",
    "        remove_these= [\"attn.masked_bias\", \".attn.bias\", \"lm_head.weight\"]\n",
    "        for suffix in remove_these:\n",
    "            if pretrainedkey.endswith(suffix):\n",
    "                break\n",
    "        else:\n",
    "            keys_to_iterate.append(pretrainedkey)\n",
    "\n",
    "    # match keys\n",
    "    remaining_keys = list(my_state.keys())\n",
    "    matched_keys = {}\n",
    "    for key in keys_to_iterate:\n",
    "        for mykey in remaining_keys:\n",
    "            if key.endswith(\"weight\") and not (key.endswith(\"wte.weight\") or key.endswith(\"wpe.weight\")):\n",
    "                # transpose shape\n",
    "                pretrained_values = pretraineddict[key].T\n",
    "                print(f\"Copied params.T: {key} -> {mykey}\")\n",
    "            else:\n",
    "                pretrained_values = pretraineddict[key]\n",
    "                print(f\"Copied params: {key} -> {mykey}\")\n",
    "\n",
    "            myshape = my_state[mykey].shape\n",
    "            if pretrained_values.shape == myshape:\n",
    "                matched_keys[mykey] = pretrained_values\n",
    "                remaining_keys.remove(mykey)\n",
    "                break\n",
    "        else: \n",
    "            print(f\"No match found for key {key}\")\n",
    "\n",
    "\n",
    "    # Check the number of params/buffers is correct\n",
    "    assert len(matched_keys) == len(keys_to_iterate), \"Number of layers is wrong. Have you done the prev step correctly?\"\n",
    "\n",
    "    # Initialise an empty dictionary to store the correct key-value pairs\n",
    "    # state_dict_to_load = {}\n",
    "\n",
    "    # for mykey, pretrainedkey in zip(matched_keys, keys_to_iterate):\n",
    "    #     pretrainedvalue = pretraineddict[pretrainedkey]\n",
    "    #     state_dict_to_load[mykey] = pretrainedvalue\n",
    "\n",
    "    my_model.load_state_dict(matched_keys)\n",
    "\n",
    "    return my_model\n",
    "\n",
    "my_gpt = copy_weights_simon(model, gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  Former President of the United States of America, George\n",
      "Your model's top 10 predictions:  [' W', ' H', ' Bush', ' Washington', ' HW', ' Herbert', ' Pat', ' Soros', ' S', ' Wallace']\n",
      "Prompt:  Former President of the United States of America, George\n",
      "Your model's top 10 predictions:  [' W', ' H', ' Bush', ' Washington', ' HW', ' Herbert', ' Pat', ' S', ' Soros', ' Wallace']\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "def test_load_pretrained_weights(model, tokenizer):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    def encode(text: str) -> t.Tensor:\n",
    "        \"\"\"Return a Tensor of shape (batch=1, seq).\"\"\"\n",
    "        return tokenizer(text, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "    prompt = \"Former President of the United States of America, George\"\n",
    "    input_ids = encode(prompt)\n",
    "    with t.inference_mode():\n",
    "        output = model(input_ids)\n",
    "        logits = output[0, -1] if isinstance(output, t.Tensor) else output.logits[0, -1]\n",
    "    topk = t.topk(logits, k=10).indices\n",
    "    next_tokens = tokenizer.batch_decode(topk.reshape(-1, 1))\n",
    "    print(\"Prompt: \", prompt)\n",
    "    print(\"Your model's top 10 predictions: \", next_tokens)\n",
    "    assert \" Washington\" in next_tokens\n",
    "    assert \" Bush\" in next_tokens\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "test_load_pretrained_weights(my_gpt, tokenizer)\n",
    "test_load_pretrained_weights(gpt2, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ded5e6f133e31c74d7e61946920be103f96969c2c9abd403ec1a6f8823efeff2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
